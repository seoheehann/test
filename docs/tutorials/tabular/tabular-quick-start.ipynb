{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "998885f294556807"
      },
      "source": [
        "# AutoGluon Tabular - Quick Start\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/tabular-quick-start.ipynb)\n",
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/tabular-quick-start.ipynb)\n",
        "\n",
        "In this tutorial, we will see how to use AutoGluon's `TabularPredictor` to predict the values of a target column based on the other columns in a tabular dataset.\n",
        "\n",
        "Begin by making sure AutoGluon is installed, and then import AutoGluon's `TabularDataset` and `TabularPredictor`. We will use the former to load data and the latter to train models and make predictions."
      ],
      "id": "998885f294556807"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "hide-output"
        ],
        "id": "f4d1edc3d2f610f6",
        "outputId": "18a04fc6-240e-4597-d690-a928f9717709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.3.1\n",
            "Collecting autogluon\n",
            "  Downloading autogluon-1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.2 (from autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading autogluon.core-1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.features==1.2 (from autogluon)\n",
            "  Downloading autogluon.features-1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
            "  Downloading autogluon.tabular-1.2-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting autogluon.multimodal==1.2 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.timeseries==1.2 (from autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading autogluon.timeseries-1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<1.5.3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.5.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.4.2)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.32.3)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.8.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading boto3-1.35.76-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting autogluon.common==1.2 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading autogluon.common-1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ray<2.40,>=2.10.0 (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading ray-2.39.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.2->autogluon) (17.0.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.2->autogluon) (0.2.7)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.2->autogluon) (11.0.0)\n",
            "Requirement already satisfied: torch<2.6,>=2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.2->autogluon) (2.5.1+cu121)\n",
            "Collecting lightning<2.6,>=2.2 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: transformers<5,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon) (4.46.3)\n",
            "Collecting accelerate<1.0,>=0.34.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: torchvision<0.21.0,>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.2->autogluon) (0.20.1+cu121)\n",
            "Requirement already satisfied: scikit-image<0.25.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.2->autogluon) (0.24.0)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.2->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting nltk<3.9,>=3.4.5 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.2->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.2->autogluon) (3.1.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.2->autogluon) (2.17.1)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: spacy<3.8 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (3.7.5)\n",
            "Requirement already satisfied: lightgbm<4.6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (4.5.0)\n",
            "Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (0.8.0)\n",
            "Requirement already satisfied: xgboost<2.2,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (2.1.3)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (2.7.18)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (0.26.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.4.2)\n",
            "Collecting pytorch-lightning (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading gluonts-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting statsforecast<1.8,>=1.7.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading statsforecast-1.7.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (28 kB)\n",
            "Collecting mlforecast==0.13.4 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading mlforecast-0.13.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting utilsforecast<0.2.5,>=0.2.3 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading utilsforecast-0.2.4-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting coreforecast==0.0.12 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading coreforecast-0.0.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.10.12)\n",
            "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (5.9.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2024.10.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.60.0)\n",
            "Collecting optuna (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (24.2)\n",
            "Collecting window-ops (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon) (0.4.5)\n",
            "Collecting botocore<1.36.0,>=1.35.76 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading botocore-1.35.76-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (1.16.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (24.3.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (1.7.22)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (1.0.3)\n",
            "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.10.3)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (4.12.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon) (1.0.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.2->autogluon) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.22.3)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.8.2)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (2024.9.11)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.16.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (4.25.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.5.0)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.11.9)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.21.1)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (7.0.5)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading virtualenv-20.28.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.68.1)\n",
            "Collecting memray (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading memray-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.8.30)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.14.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.1.3)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=4.38.0->transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon) (0.20.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon) (0.2.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost<2.2,>=1.6->autogluon.tabular[all]==1.2->autogluon) (2.23.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.4.4)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (4.0.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.18.3)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (4.12.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.27.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.0.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.1.5)\n",
            "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (2.18.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (4.3.6)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.20.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.17.0)\n",
            "Collecting textual>=0.41.0 (from memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading textual-0.89.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.19.2)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.0.36)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (9.0.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.25.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.27.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.1.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (2.6)\n",
            "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting filelock (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (4.9)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.4.2)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.6.1)\n",
            "Downloading autogluon-1.2-py3-none-any.whl (9.6 kB)\n",
            "Downloading autogluon.core-1.2-py3-none-any.whl (266 kB)\n",
            "Downloading autogluon.features-1.2-py3-none-any.whl (64 kB)\n",
            "Downloading autogluon.multimodal-1.2-py3-none-any.whl (429 kB)\n",
            "Downloading autogluon.tabular-1.2-py3-none-any.whl (352 kB)\n",
            "Downloading autogluon.timeseries-1.2-py3-none-any.whl (174 kB)\n",
            "Downloading autogluon.common-1.2-py3-none-any.whl (68 kB)\n",
            "Downloading coreforecast-0.0.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (196 kB)\n",
            "Downloading mlforecast-0.13.4-py3-none-any.whl (70 kB)\n",
            "Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
            "Downloading boto3-1.35.76-py3-none-any.whl (139 kB)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "Downloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
            "Downloading gluonts-0.16.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "Downloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
            "Downloading ray-2.39.0-cp310-cp310-manylinux2014_x86_64.whl (66.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-1.7.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (314 kB)\n",
            "Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.2.4-py3-none-any.whl (40 kB)\n",
            "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
            "Downloading botocore-1.35.76-py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "Downloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
            "Downloading virtualenv-20.28.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "Downloading memray-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading textual-0.89.1-py3-none-any.whl (656 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.0/656.0 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "Downloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "Building wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19173 sha256=2dd960023783f7840f747f423b3dbc43cacecf1f67fc9c18d1262d7b0c5bb17d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=3baa5fab4d1c331c48d7b67ffe06dbcf570dbc7b8a4aaf3b889358b87109f8e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=d2855172cf3f34b6c275ab274592aa3d1796b59e9d0ddcf86889228d1b20b4b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, appdirs, antlr4-python3-runtime, xxhash, virtualenv, tensorboardX, pytesseract, pycryptodome, pdf2image, ordered-set, openxlab, omegaconf, nltk, Mako, lightning-utilities, jmespath, fsspec, fs, dill, coreforecast, colorlog, colorama, window-ops, multiprocess, model-index, botocore, alembic, utilsforecast, triad, torchmetrics, seqeval, s3transfer, pytorch-metric-learning, optuna, opendatalab, jsonschema, gluonts, catboost, accelerate, timm, textual, ray, openmim, opencensus, nlpaug, mlforecast, boto3, aiohttp-cors, adagio, pytorch-lightning, memray, fugue, datasets, autogluon.common, statsforecast, lightning, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.23.0\n",
            "    Uninstalling jsonschema-4.23.0:\n",
            "      Successfully uninstalled jsonschema-4.23.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.1.1\n",
            "    Uninstalling accelerate-1.1.1:\n",
            "      Successfully uninstalled accelerate-1.1.1\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.12\n",
            "    Uninstalling timm-1.0.12:\n",
            "      Successfully uninstalled timm-1.0.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.8 accelerate-0.34.2 adagio-0.2.6 aiohttp-cors-0.7.0 alembic-1.14.0 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 autogluon-1.2 autogluon.common-1.2 autogluon.core-1.2 autogluon.features-1.2 autogluon.multimodal-1.2 autogluon.tabular-1.2 autogluon.timeseries-1.2 boto3-1.35.76 botocore-1.35.76 catboost-1.2.7 colorama-0.4.6 colorful-0.5.6 colorlog-6.9.0 coreforecast-0.0.12 datasets-3.1.0 dill-0.3.8 distlib-0.3.9 evaluate-0.4.3 fs-2.4.16 fsspec-2024.9.0 fugue-0.9.1 gluonts-0.16.0 jmespath-1.0.1 jsonschema-4.21.1 lightning-2.4.0 lightning-utilities-0.11.9 memray-1.15.0 mlforecast-0.13.4 model-index-0.1.11 multiprocess-0.70.16 nlpaug-1.1.11 nltk-3.8.1 nvidia-ml-py3-7.352.0 omegaconf-2.2.3 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.1.0 ordered-set-4.1.0 pdf2image-1.17.0 py-spy-0.4.0 pycryptodome-3.21.0 pytesseract-0.3.10 pytorch-lightning-2.4.0 pytorch-metric-learning-2.3.0 ray-2.39.0 s3transfer-0.10.4 seqeval-1.2.2 statsforecast-1.7.8 tensorboardX-2.6.2.2 textual-0.89.1 timm-1.0.3 torchmetrics-1.2.1 triad-0.9.8 utilsforecast-0.2.4 virtualenv-20.28.0 window-ops-0.0.15 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!python -m pip install autogluon"
      ],
      "id": "f4d1edc3d2f610f6"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ff904c9d1af0ac39"
      },
      "outputs": [],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ],
      "id": "ff904c9d1af0ac39"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e42b07bc64929c80"
      },
      "source": [
        "## Example Data"
      ],
      "id": "e42b07bc64929c80"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f247a5c20c9be613"
      },
      "source": [
        "For this tutorial we will use a dataset from the cover story of [Nature issue 7887](https://www.nature.com/nature/volumes/600/issues/7887): [AI-guided intuition for math theorems](https://www.nature.com/articles/s41586-021-04086-x.pdf). The goal is to predict a knot's signature based on its properties. We sampled 10K training and 5K test examples from the [original data](https://github.com/deepmind/mathematics_conjectures/blob/main/knot_theory.ipynb). The sampled dataset make this tutorial run quickly, but AutoGluon can handle the full dataset if desired.\n",
        "\n",
        "We load this dataset directly from a URL. AutoGluon's `TabularDataset` is a subclass of pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html), so any `DataFrame` methods can be used on `TabularDataset` as well."
      ],
      "id": "f247a5c20c9be613"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bfda6620a2f2637",
        "outputId": "981a37a3-6361-40d8-a5a6-1f6d1cc04b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              시간단위         격자명     인구수  경로당 수  복지시설 개수  보호지역 유무  과속단속카메라 개수  \\\n",
              "0  2020.01~2020.06  ë¤ì¬6453  1776.0    2.0      1.0      0.0         3.0   \n",
              "1  2020.01~2020.06  ë¤ì¬5651  2908.0    2.0      1.0      0.0         4.0   \n",
              "2  2020.01~2020.06  ë¤ì¬6157  6798.0    4.0      1.0      0.0         3.0   \n",
              "3  2020.01~2020.06  ë¤ì¬5858  5687.0    3.0      1.0      0.0         4.0   \n",
              "4  2020.01~2020.06  ë¤ì¬5347  2394.0    2.0      1.0      0.0         1.0   \n",
              "\n",
              "    EPDO  사고수  EPDO 정규화   사고수 정규화      종속변수    종속  Unnamed: 13   인구수 정규화  \\\n",
              "0   23.0  1.0  0.048319  0.000000  0.014496   5.4          NaN  0.192499   \n",
              "1  137.0  1.0  0.287815  0.000000  0.086345  28.2          NaN  0.315196   \n",
              "2  127.0  2.0  0.266807  0.111111  0.157820  27.0          NaN  0.736831   \n",
              "3  185.0  2.0  0.388655  0.111111  0.194374  38.6          NaN  0.616410   \n",
              "4   57.0  1.0  0.119748  0.000000  0.035924  12.2          NaN  0.259484   \n",
              "\n",
              "   경로당 정규화  복지시설 정규화  과속단속 정규화  \n",
              "0    0.250       0.0  0.103448  \n",
              "1    0.250       0.0  0.137931  \n",
              "2    0.500       0.0  0.103448  \n",
              "3    0.375       0.0  0.137931  \n",
              "4    0.250       0.0  0.034483  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3415ed85-47d9-417f-81d8-b44488251fe9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>시간단위</th>\n",
              "      <th>격자명</th>\n",
              "      <th>인구수</th>\n",
              "      <th>경로당 수</th>\n",
              "      <th>복지시설 개수</th>\n",
              "      <th>보호지역 유무</th>\n",
              "      <th>과속단속카메라 개수</th>\n",
              "      <th>EPDO</th>\n",
              "      <th>사고수</th>\n",
              "      <th>EPDO 정규화</th>\n",
              "      <th>사고수 정규화</th>\n",
              "      <th>종속변수</th>\n",
              "      <th>종속</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "      <th>인구수 정규화</th>\n",
              "      <th>경로당 정규화</th>\n",
              "      <th>복지시설 정규화</th>\n",
              "      <th>과속단속 정규화</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020.01~2020.06</td>\n",
              "      <td>ë¤ì¬6453</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.048319</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014496</td>\n",
              "      <td>5.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.192499</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020.01~2020.06</td>\n",
              "      <td>ë¤ì¬5651</td>\n",
              "      <td>2908.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.287815</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086345</td>\n",
              "      <td>28.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.315196</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020.01~2020.06</td>\n",
              "      <td>ë¤ì¬6157</td>\n",
              "      <td>6798.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.266807</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.157820</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.736831</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020.01~2020.06</td>\n",
              "      <td>ë¤ì¬5858</td>\n",
              "      <td>5687.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.388655</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.194374</td>\n",
              "      <td>38.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.616410</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020.01~2020.06</td>\n",
              "      <td>ë¤ì¬5347</td>\n",
              "      <td>2394.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.119748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035924</td>\n",
              "      <td>12.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.259484</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3415ed85-47d9-417f-81d8-b44488251fe9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3415ed85-47d9-417f-81d8-b44488251fe9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3415ed85-47d9-417f-81d8-b44488251fe9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-986b2e5b-ecf5-4f0b-a70d-45e281874966\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-986b2e5b-ecf5-4f0b-a70d-45e281874966')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-986b2e5b-ecf5-4f0b-a70d-45e281874966 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 4267,\n  \"fields\": [\n    {\n      \"column\": \"\\uc2dc\\uac04\\ub2e8\\uc704\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2020.01~2020.06\",\n          \"2020.07~2020.12\",\n          \"2022.07~2022.12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uaca9\\uc790\\uba85\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 710,\n        \"samples\": [\n          \"\\u00eb\\u008b\\u00a4\\u00ec\\u0082\\u00ac4652\",\n          \"\\u00eb\\u008b\\u00a4\\u00ec\\u0082\\u00ac5244\",\n          \"\\u00eb\\u008b\\u00a4\\u00ec\\u0082\\u00ac5358\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc778\\uad6c\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2292.611178402238,\n        \"min\": 0.0,\n        \"max\": 9226.0,\n        \"num_unique_values\": 2825,\n        \"samples\": [\n          3485.0,\n          5801.0,\n          6918.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uacbd\\ub85c\\ub2f9 \\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7827725971463846,\n        \"min\": 0.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          8.0,\n          4.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ubcf5\\uc9c0\\uc2dc\\uc124 \\uac1c\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4332329085164282,\n        \"min\": 1.0,\n        \"max\": 26.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          10.0,\n          25.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ubcf4\\ud638\\uc9c0\\uc5ed \\uc720\\ubb34\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.39393399940916496,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uacfc\\uc18d\\ub2e8\\uc18d\\uce74\\uba54\\ub77c \\uac1c\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.071593521268354,\n        \"min\": 0.0,\n        \"max\": 29.0,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          14.0,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EPDO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71.07059502563966,\n        \"min\": 0.0,\n        \"max\": 476.0,\n        \"num_unique_values\": 312,\n        \"samples\": [\n          48.0,\n          76.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc0ac\\uace0\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7456161390023062,\n        \"min\": 1.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          8.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EPDO \\uc815\\uaddc\\ud654\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1487488443748638,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 312,\n        \"samples\": [\n          0.10084033613445378,\n          0.15966386554621848\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc0ac\\uace0\\uc218 \\uc815\\uaddc\\ud654\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08151412292522366,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.7777777777777778,\n          0.1111111111111111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc885\\uc18d\\ubcc0\\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07843860995698816,\n        \"min\": 0.0,\n        \"max\": 0.7989495798319327,\n        \"num_unique_values\": 668,\n        \"samples\": [\n          0.1468487394957983,\n          0.319047619047619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc885\\uc18d\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.263020503247628,\n        \"min\": 0.0,\n        \"max\": 96.0,\n        \"num_unique_values\": 418,\n        \"samples\": [\n          44.4,\n          41.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc778\\uad6c\\uc218 \\uc815\\uaddc\\ud654\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24836842184968702,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2825,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uacbd\\ub85c\\ub2f9 \\uc815\\uaddc\\ud654\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22260112913259822,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ubcf5\\uc9c0\\uc2dc\\uc124 \\uc815\\uaddc\\ud654\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053184162745758684,\n        \"min\": -0.038461538461538464,\n        \"max\": 0.9615384615384616,\n        \"num_unique_values\": 14,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uacfc\\uc18d\\ub2e8\\uc18d \\uc815\\uaddc\\ud654\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13973780593807686,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 25,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularDataset\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Excel 파일을 pandas로 불러오기\n",
        "file_path = '/content/drive/MyDrive/노인보호구역 프로젝트/p프_전체계획.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# TabularDataset에 전달\n",
        "train_data = TabularDataset(df)\n",
        "\n",
        "# 데이터 확인\n",
        "train_data.head()\n"
      ],
      "id": "bfda6620a2f2637"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c810125a2b8aa286"
      },
      "source": [
        "Our targets are stored in the \"signature\" column, which has 18 unique integers. Even though pandas didn't correctly recognize this data type as categorical, AutoGluon will fix this issue.\n"
      ],
      "id": "c810125a2b8aa286"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "735d0a050b701f31",
        "outputId": "bcc1f225-1d55-49a7-aeff-32cba4141882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    4265.000000\n",
              "mean       14.622884\n",
              "std        14.263021\n",
              "min         0.000000\n",
              "25%         2.600000\n",
              "50%        11.000000\n",
              "75%        22.200000\n",
              "max        96.000000\n",
              "Name: 종속, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>종속</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4265.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.622884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.263021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>22.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>96.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "label = '종속'\n",
        "train_data[label].describe()"
      ],
      "id": "735d0a050b701f31"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec8a61ef4291bc39"
      },
      "source": [
        "## Training\n",
        "\n",
        "We now construct a `TabularPredictor` by specifying the label column name and then train on the dataset with `TabularPredictor.fit()`. We don't need to specify any other parameters. AutoGluon will recognize this is a multi-class classification task, perform automatic feature engineering, train multiple models, and then ensemble the models to create the final predictor."
      ],
      "id": "ec8a61ef4291bc39"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [
          "hide-output"
        ],
        "id": "362ff589bb29d77d",
        "outputId": "d85bba9e-de5f-45f6-8ec4-d6162ce91bb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_030230\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.12 GB / 12.67 GB (87.7%)\n",
            "Disk Space Avail:   74.21 GB / 107.72 GB (68.9%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_030230\"\n",
            "Train Data Rows:    4267\n",
            "Train Data Columns: 17\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.62288, 14.25968)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11385.89 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.22 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['Unnamed: 13']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 14 | ['인구수', '경로당 수', '복지시설 개수', '보호지역 유무', '과속단속카메라 개수', ...]\n",
            "\t\t('object', []) :  2 | ['시간단위', '격자명']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['시간단위', '격자명']\n",
            "\t\t('float', [])    : 14 | ['인구수', '경로당 수', '복지시설 개수', '보호지역 유무', '과속단속카메라 개수', ...]\n",
            "\t0.1s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.47 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.21s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.11717834544176237, Train Rows: 3767, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-3.3204\t = Validation score   (-root_mean_squared_error)\n",
            "\t6.34s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-3.0893\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.705232\n",
            "[2000]\tvalid_set's rmse: 0.682381\n",
            "[3000]\tvalid_set's rmse: 0.666128\n",
            "[4000]\tvalid_set's rmse: 0.659256\n",
            "[5000]\tvalid_set's rmse: 0.65547\n",
            "[6000]\tvalid_set's rmse: 0.650612\n",
            "[7000]\tvalid_set's rmse: 0.646945\n",
            "[8000]\tvalid_set's rmse: 0.644815\n",
            "[9000]\tvalid_set's rmse: 0.642239\n",
            "[10000]\tvalid_set's rmse: 0.641013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.641\t = Validation score   (-root_mean_squared_error)\n",
            "\t17.09s\t = Training   runtime\n",
            "\t1.54s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-2.6998\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.86s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.5808\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.64s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.1659\t = Validation score   (-root_mean_squared_error)\n",
            "\t178.17s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.8264\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.84s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.8916\t = Validation score   (-root_mean_squared_error)\n",
            "\t7.87s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-2.6208\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.05s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-1.1036\t = Validation score   (-root_mean_squared_error)\n",
            "\t22.76s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-2.8896\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.19s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'CatBoost': 1.0}\n",
            "\t-0.1659\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 247.99s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 17685.4 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_030230\")\n"
          ]
        }
      ],
      "source": [
        "predictor = TabularPredictor(label=label).fit(train_data)"
      ],
      "id": "362ff589bb29d77d"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
        "\n",
        "hyperparameters = {\n",
        "    'RF': {'num_trees': 50, 'max_depth': 5},  # Random Forest 모델에서 트리 수나 깊이를 줄여서 과적합을 방지\n",
        "    'GBM': {'num_boost_round': 50, 'max_depth': 5},  # Gradient Boosting에서 학습을 더 적게 진행\n",
        "    'NN': {'epochs': 5, 'batch_size': 32}  # Neural Network의 학습 epoch을 줄임\n",
        "}\n",
        "\n",
        "predictor = TabularPredictor(label=label).fit(train_data, hyperparameters=hyperparameters)\n",
        "\n",
        "\n",
        "# 예측 수행\n",
        "y_pred = predictor.predict(train_data.drop(columns=[label]))\n",
        "y_true = train_data[label]\n",
        "\n",
        "# 성능 지표 계산\n",
        "rmse = mean_squared_error(y_true, y_pred, squared=False)  # RMSE\n",
        "mae = mean_absolute_error(y_true, y_pred)               # MAE\n",
        "r2 = r2_score(y_true, y_pred)                           # R²\n",
        "mape = (abs((y_true - y_pred) / y_true).mean()) * 100   # MAPE (%)\n",
        "explained_var = explained_variance_score(y_true, y_pred)  # Explained Variance\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(f\"1. RMSE (Root Mean Squared Error): {rmse:.4f}\")\n",
        "print(f\"2. MAE (Mean Absolute Error): {mae:.4f}\")\n",
        "print(f\"3. R² (Coefficient of Determination): {r2:.4f}\")\n",
        "print(f\"4. MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
        "print(f\"5. Explained Variance: {explained_var:.4f}\")"
      ],
      "metadata": {
        "id": "cp0vvbBWZJbm",
        "outputId": "b833f6ef-fb37-41e7-a6ad-f5a3fa5ca7ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "cp0vvbBWZJbm",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_064814\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.59 GB / 12.67 GB (83.5%)\n",
            "Disk Space Avail:   72.88 GB / 107.72 GB (67.7%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_064814\"\n",
            "Train Data Rows:    3555\n",
            "Train Data Columns: 15\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.71893, 14.43737)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10840.07 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.90 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['Unnamed: 13']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t\t('object', []) :  2 | ['시간단위', '격자명']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['시간단위', '격자명']\n",
            "\t\t('float', [])    : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t0.4s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.47s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14064697609001406, Train Rows: 3055, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'RF': [{'num_trees': 50, 'max_depth': 5}],\n",
            "\t'GBM': [{'num_boost_round': 50, 'max_depth': 5}],\n",
            "\t'NN': [{'epochs': 5, 'batch_size': 32}],\n",
            "}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Unknown model type specified in hyperparameters: 'NN'. Valid model types: ['RF', 'XT', 'KNN', 'GBM', 'CAT', 'XGB', 'NN_TORCH', 'LR', 'FASTAI', 'TRANSF', 'AG_TEXT_NN', 'AG_IMAGE_NN', 'AG_AUTOMM', 'FT_TRANSFORMER', 'TABPFN', 'TABPFNMIX', 'FASTTEXT', 'ENS_WEIGHTED', 'SIMPLE_ENS_WEIGHTED', 'IM_RULEFIT', 'IM_GREEDYTREE', 'IM_FIGS', 'IM_HSTREE', 'IM_BOOSTEDRULES', 'VW', 'DUMMY']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-1b100288ea83>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save predictor to disk to enable prediction and training after interrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_post_fit_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Learner is already fit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     def _fit(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/learner/default_learner.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, X_val, X_test, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         trainer.fit(\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/trainer/auto_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_test, y_test, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         self._train_multi_and_ensemble(\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, X_test, y_test, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   3236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_rows_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_cols_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3238\u001b[0;31m         model_names_fit = self.train_multi_levels(\n\u001b[0m\u001b[1;32m   3239\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mtrain_multi_levels\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_test, y_test, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size, callbacks)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                 \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_aux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             base_model_names, aux_models = self.stack_new_level(\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level\u001b[0;34m(self, X, y, models, X_val, y_val, X_test, y_test, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size, full_weighted_ensemble, additional_full_weighted_ensemble)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name_suffix\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         core_models = self.stack_new_level_core(\n\u001b[0m\u001b[1;32m    689\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_test, y_test, X_unlabeled, level, base_model_names, fit_strategy, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     )\n\u001b[1;32m    802\u001b[0m                 )\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_args_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_models_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mget_models_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_args_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                 hyperparameter_tune_kwargs = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/trainer/auto_trainer.py\u001b[0m in \u001b[0;36mconstruct_model_templates\u001b[0;34m(self, hyperparameters, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mag_args_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"quantile_levels\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantile_levels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         return get_preset_models(\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mproblem_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproblem_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/trainer/model_presets/presets.py\u001b[0m in \u001b[0;36mget_preset_models\u001b[0;34m(path, problem_type, eval_metric, hyperparameters, level, ensemble_type, ensemble_kwargs, ag_args_fit, ag_args, ag_args_ensemble, name_suffix, default_priorities, invalid_model_names, included_model_types, excluded_model_types, hyperparameter_preprocess_func, hyperparameter_preprocess_kwargs, silent)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mmodel_cfgs_to_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_cfg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_cfgs_to_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             model_cfg = clean_model_cfg(\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0mmodel_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/trainer/model_presets/presets.py\u001b[0m in \u001b[0;36mclean_model_cfg\u001b[0;34m(model_cfg, model_type, ag_args, ag_args_ensemble, ag_args_fit, problem_type)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unknown model type specified in hyperparameters: '{model_type}'. Valid model types: {list(MODEL_TYPES.keys())}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODEL_TYPES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAbstractModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Unknown model type specified in hyperparameters: 'NN'. Valid model types: ['RF', 'XT', 'KNN', 'GBM', 'CAT', 'XGB', 'NN_TORCH', 'LR', 'FASTAI', 'TRANSF', 'AG_TEXT_NN', 'AG_IMAGE_NN', 'AG_AUTOMM', 'FT_TRANSFORMER', 'TABPFN', 'TABPFNMIX', 'FASTTEXT', 'ENS_WEIGHTED', 'SIMPLE_ENS_WEIGHTED', 'IM_RULEFIT', 'IM_GREEDYTREE', 'IM_FIGS', 'IM_HSTREE', 'IM_BOOSTEDRULES', 'VW', 'DUMMY']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
        "import numpy as np\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 교차 검증 설정\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "metrics = {\n",
        "    \"RMSE\": [],\n",
        "    \"MAE\": [],\n",
        "    \"R²\": [],\n",
        "    \"Explained Variance\": []\n",
        "}\n",
        "\n",
        "# 데이터와 레이블 분리\n",
        "X = train_data.drop(columns=[label])\n",
        "y = train_data[label]\n",
        "\n",
        "# 교차 검증 반복\n",
        "for train_index, val_index in kfold.split(X):\n",
        "    # 훈련/검증 데이터 분할\n",
        "    train_fold = train_data.iloc[train_index]\n",
        "    val_fold = train_data.iloc[val_index]\n",
        "\n",
        "    # AutoGluon 훈련\n",
        "    predictor = TabularPredictor(label=label).fit(train_fold, presets='medium', verbosity=0)\n",
        "\n",
        "    # WeightedEnsemble_L2 모델로 예측\n",
        "    y_val_true = val_fold[label]\n",
        "    y_val_pred = predictor.predict(val_fold.drop(columns=[label]))\n",
        "\n",
        "    # 성능 지표 계산\n",
        "    metrics[\"RMSE\"].append(mean_squared_error(y_val_true, y_val_pred, squared=False))\n",
        "    metrics[\"MAE\"].append(mean_absolute_error(y_val_true, y_val_pred))\n",
        "    metrics[\"R²\"].append(r2_score(y_val_true, y_val_pred))\n",
        "    metrics[\"Explained Variance\"].append(explained_variance_score(y_val_true, y_val_pred))\n",
        "\n",
        "# 평균 성능 지표 출력\n",
        "print(\"Cross-Validation Metrics:\")\n",
        "print(f\"1. RMSE: {np.mean(metrics['RMSE']):.4f}\")\n",
        "print(f\"2. MAE: {np.mean(metrics['MAE']):.4f}\")\n",
        "print(f\"3. R²: {np.mean(metrics['R²']):.4f}\")\n",
        "print(f\"4. Explained Variance: {np.mean(metrics['Explained Variance']):.4f}\")\n"
      ],
      "metadata": {
        "id": "AQ1OirnhZuI3",
        "outputId": "f7f45c64-fce8-4f7c-f2dd-a0df375af56f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AQ1OirnhZuI3",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_031223\"\n",
            "Preset alias specified: 'medium' maps to 'medium_quality'.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_031639\"\n",
            "Preset alias specified: 'medium' maps to 'medium_quality'.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_032011\"\n",
            "Preset alias specified: 'medium' maps to 'medium_quality'.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_032400\"\n",
            "Preset alias specified: 'medium' maps to 'medium_quality'.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_032514\"\n",
            "Preset alias specified: 'medium' maps to 'medium_quality'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Metrics:\n",
            "1. RMSE: 0.4365\n",
            "2. MAE: 0.0714\n",
            "3. R²: 0.9987\n",
            "4. Explained Variance: 0.9987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(train_data[label].isna().sum())  # NaN 값 개수\n",
        "print(train_data[~np.isfinite(train_data[label])])  # Inf 또는 Ninf 값 확인\n",
        "\n",
        "# 결측값 대체 (예: 평균값으로 대체)\n",
        "mean_value = train_data[label].mean()  # 평균값 계산\n",
        "train_data[label] = train_data[label].fillna(mean_value)\n",
        "\n",
        "# 비정상 값 처리 (Inf, -Inf를 평균값으로 대체)\n",
        "train_data[label] = np.where(np.isfinite(train_data[label]), train_data[label], mean_value)\n"
      ],
      "metadata": {
        "id": "zpmPQa-vXTgy",
        "outputId": "9361299d-c282-4774-bc4d-f00eca1dcb7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zpmPQa-vXTgy",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Empty DataFrame\n",
            "Columns: [시간단위, 격자명, 인구수, 경로당 수, 복지시설 개수, 보호지역 유무, 과속단속카메라 개수, EPDO, 사고수, EPDO 정규화, 사고수 정규화, 종속변수, 종속, Unnamed: 13, 인구수 정규화, 경로당 정규화, 복지시설 정규화, 과속단속 정규화]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a0c76c9931ef02a"
      },
      "source": [
        "Model fitting should take a few minutes or less depending on your CPU. You can make training faster by specifying the `time_limit` argument. For example, `fit(..., time_limit=60)` will stop training after 60 seconds. Higher time limits will generally result in better prediction performance, and excessively low time limits will prevent AutoGluon from training and ensembling a reasonable set of models.\n",
        "\n"
      ],
      "id": "1a0c76c9931ef02a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a14b3b77951c8885"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "Once we have a predictor that is fit on the training dataset, we can load a separate set of data to use for prediction and evaulation."
      ],
      "id": "a14b3b77951c8885"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "71c5ca4d79e46793",
        "outputId": "7e9df6a2-0aa9-421d-c84b-eb0955012173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/train_data.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-24e187c69819>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 예시: 정규화 계산 방식\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/train_data.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/TEST DATA.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 예시로 '인구수' 열에 대해 정규화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/train_data.xlsx'"
          ]
        }
      ],
      "source": [
        "# 예시: 정규화 계산 방식\n",
        "train_data_df = pd.read_excel('/content/drive/MyDrive/train_data.xlsx')\n",
        "test_data_df = pd.read_excel('/content/drive/MyDrive/TEST DATA.xlsx')\n",
        "\n",
        "# 예시로 '인구수' 열에 대해 정규화\n",
        "mean_population = train_data_df['인구수'].mean()\n",
        "std_population = train_data_df['인구수'].std()\n",
        "\n",
        "# 테스트 데이터에도 동일한 방식으로 정규화 적용\n",
        "test_data_df['인구수 정규화'] = (test_data_df['인구수'] - mean_population) / std_population\n",
        "\n",
        "# 다른 변수들도 동일한 방식으로 정규화 처리\n",
        "mean_facility = train_data_df['경로당 수'].mean()\n",
        "std_facility = train_data_df['경로당 수'].std()\n",
        "test_data_df['경로당 정규화'] = (test_data_df['경로당 수'] - mean_facility) / std_facility\n",
        "\n",
        "# 필요한 모든 정규화 열을 추가 후, TabularDataset으로 변환\n",
        "test_data = TabularDataset(test_data_df)"
      ],
      "id": "71c5ca4d79e46793"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a07dc2dd8e3225a"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "We can evaluate the predictor on the test dataset using the `evaluate()` function, which measures how well our predictor performs on data that was not used for fitting the models."
      ],
      "id": "a07dc2dd8e3225a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95d51e36939dcc95"
      },
      "outputs": [],
      "source": [
        "predictor.evaluate(test_data, silent=True)"
      ],
      "id": "95d51e36939dcc95"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23ad005fd976a13e"
      },
      "source": [
        "AutoGluon's `TabularPredictor` also provides the `leaderboard()` function, which allows us to evaluate the performance of each individual trained model on the test data."
      ],
      "id": "23ad005fd976a13e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43a52983e6d38da1"
      },
      "outputs": [],
      "source": [
        "predictor.leaderboard(test_data)"
      ],
      "id": "43a52983e6d38da1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79eb2f75ce0e5eed"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this quickstart tutorial we saw AutoGluon's basic fit and predict functionality using `TabularDataset` and `TabularPredictor`. AutoGluon simplifies the model training process by not requiring feature engineering or model hyperparameter tuning. Check out the in-depth tutorials to learn more about AutoGluon's other features like customizing the training and prediction steps or extending AutoGluon with custom feature generators, models, or metrics."
      ],
      "id": "79eb2f75ce0e5eed"
    },
    {
      "cell_type": "markdown",
      "source": [
        "WeightedL2"
      ],
      "metadata": {
        "id": "eV1Xocs2yanS"
      },
      "id": "eV1Xocs2yanS"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import autogluon.core as ag\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 데이터 불러오기\n",
        "train_data = pd.read_excel('/content/drive/MyDrive/노인보호구역 프로젝트/p프_전체계획.xlsx')\n",
        "test_data = pd.read_excel('/content/drive/MyDrive/노인보호구역 프로젝트/TEST DATA.xlsx')\n",
        "\n",
        "# 독립변수 및 종속변수 설정\n",
        "features = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "target = '종속'  # 종속 변수 이름에 맞게 설정\n",
        "\n",
        "# 모델 학습\n",
        "predictor = TabularPredictor(label=target).fit(train_data[features + [target]])\n",
        "\n",
        "# TEST DATA 예측\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 상위 5% 위험도 계산\n",
        "top_5_percent = test_data['위험도'].quantile(0.95)\n",
        "\n",
        "# 상위 5% 위험도를 가진 격자에 대해 보호구역 설치 여부 설정\n",
        "test_data['보호구역 설치 여부'] = test_data['위험도'].apply(lambda x: '예' if x >= top_5_percent else '아니오')\n",
        "\n",
        "# 결과를 엑셀로 저장\n",
        "test_data.to_excel('예측결과_보호구역설치.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "40OaItr9yaWq",
        "outputId": "7290bee5-8371-45b6-f44f-69a957a25115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "40OaItr9yaWq",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_064936\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.54 GB / 12.67 GB (83.1%)\n",
            "Disk Space Avail:   72.88 GB / 107.72 GB (67.7%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_064936\"\n",
            "Train Data Rows:    3555\n",
            "Train Data Columns: 5\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.71893, 14.43737)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10788.21 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.14 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 5 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 5 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\t0.2s = Fit runtime\n",
            "\t5 features in original data used to generate 5 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.14 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.29s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14064697609001406, Train Rows: 3055, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-15.7137\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.09s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-15.7212\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.07s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 13.3498\n",
            "[2000]\tvalid_set's rmse: 13.2353\n",
            "[3000]\tvalid_set's rmse: 13.2088\n",
            "[4000]\tvalid_set's rmse: 13.2082\n",
            "[5000]\tvalid_set's rmse: 13.1911\n",
            "[6000]\tvalid_set's rmse: 13.1862\n",
            "[7000]\tvalid_set's rmse: 13.1878\n",
            "[8000]\tvalid_set's rmse: 13.1912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-13.175\t = Validation score   (-root_mean_squared_error)\n",
            "\t10.12s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-13.0301\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.18s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-12.8999\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.41s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-12.8942\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.54s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-12.8982\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.4s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-13.6015\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.45s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-12.7454\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.78s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-13.5279\t = Validation score   (-root_mean_squared_error)\n",
            "\t90.51s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-12.9225\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'XGBoost': 0.471, 'ExtraTreesMSE': 0.353, 'RandomForestMSE': 0.118, 'NeuralNetTorch': 0.059}\n",
            "\t-12.4959\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 125.61s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2003.9 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_064936\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 저장된 모델 불러오기\n",
        "predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_051908\")\n",
        "\n",
        "# TEST DATA 불러오기\n",
        "test_data = pd.read_excel('/content/drive/MyDrive/노인보호구역 프로젝트/TEST DATA.xlsx')\n",
        "\n",
        "# 예측할 독립변수 지정\n",
        "features = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 예측 결과 생성\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 예측 결과 확인\n",
        "print(test_data[['위험도']].head())\n",
        "\n",
        "test_data.to_excel('예측결과_보호구역설치.xlsx', index=False)"
      ],
      "metadata": {
        "id": "waSBXQi63rO7",
        "outputId": "d8db2405-5797-4c21-9d8e-381f615b3176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "waSBXQi63rO7",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         위험도\n",
            "0  16.828463\n",
            "1  20.893976\n",
            "2  18.048553\n",
            "3  20.337183\n",
            "4  12.230529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# 저장된 모델 불러오기\n",
        "predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_051908\")\n",
        "\n",
        "# TEST DATA 불러오기\n",
        "test_data = pd.read_excel('/content/drive/MyDrive/노인보호구역 프로젝트/TEST DATA.xlsx')\n",
        "\n",
        "# 예측할 독립변수 지정\n",
        "features = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 실제 종속값 (기존 '종속열') 추출\n",
        "y_true = test_data['종속']  # 실제 종속값 이름에 맞게 수정\n",
        "\n",
        "# 예측 결과 생성\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 위험도 기준으로 상위 5% 예측\n",
        "top_5_percent = test_data['위험도'].quantile(0.95)\n",
        "test_data['보호구역 설치 여부'] = test_data['위험도'].apply(lambda x: 1 if x >= top_5_percent else 0)\n",
        "\n",
        "# 예측값 (보호구역 설치 여부) 추출\n",
        "y_pred = test_data['보호구역 설치 여부']\n",
        "\n",
        "# 성능 지표 계산\n",
        "#accuracy = accuracy_score(y_true, y_pred)\n",
        "#precision = precision_score(y_true, y_pred)\n",
        "#recall = recall_score(y_true, y_pred)\n",
        "#f1 = f1_score(y_true, y_pred)\n",
        "#roc_auc = roc_auc_score(y_true, test_data['위험도'])  # AUC는 확률 값이나 점수로 계산\n",
        "\n",
        "# 성능 지표 출력\n",
        "#print(f\"정확도 (Accuracy): {accuracy:.4f}\")\n",
        "#print(f\"정밀도 (Precision): {precision:.4f}\")\n",
        "#print(f\"재현율 (Recall): {recall:.4f}\")\n",
        "#print(f\"F1 점수 (F1 Score): {f1:.4f}\")\n",
        "#print(f\"AUC 점수 (ROC AUC): {roc_auc:.4f}\")\n",
        "\n",
        "# 예측 결과를 엑셀로 저장\n",
        "test_data.to_excel('예측결과_보호구역설치.xlsx', index=False)"
      ],
      "metadata": {
        "id": "UlS4VTs-5JCX"
      },
      "id": "UlS4VTs-5JCX",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ],
      "metadata": {
        "id": "wYvngwBD55hP"
      },
      "id": "wYvngwBD55hP",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. TEST DATA에서 위험도 예측\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 5. 위험도 상위 5% 구역을 '보호구역 설치 여부' 열에 '예' 또는 '아니오'로 설정\n",
        "top_5_percent = test_data['위험도'].quantile(0.95)\n",
        "test_data['보호구역 설치 여부'] = test_data['위험도'].apply(lambda x: '예' if x >= top_5_percent else '아니오')\n",
        "\n",
        "# 6. 성능 지표 출력 (필요 시 실제 종속값이 있는 경우 적용)\n",
        "# 실제 종속값을 'TEST DATA.xlsx'에서 가져와야 함\n",
        "y_true = test_data['종속']  # 실제 종속 변수 이름에 맞게 수정\n",
        "\n",
        "# 예측값 (위험도 기준에 따른 보호구역 설치 여부)\n",
        "y_pred = test_data['보호구역 설치 여부'].apply(lambda x: 1 if x == '예' else 0)\n",
        "\n",
        "# 성능 지표 계산 (만약 실제 종속값이 있다면 사용)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "# precision = precision_score(y_true, y_pred)\n",
        "# recall = recall_score(y_true, y_pred)\n",
        "# f1 = f1_score(y_true, y_pred)\n",
        "# roc_auc = roc_auc_score(y_true, test_data['위험도'])\n",
        "\n",
        "# 성능 지표 출력 (실제 값이 있을 경우)\n",
        "# print(f\"정확도 (Accuracy): {accuracy:.4f}\")\n",
        "# print(f\"정밀도 (Precision): {precision:.4f}\")\n",
        "# print(f\"재현율 (Recall): {recall:.4f}\")\n",
        "# print(f\"F1 점수 (F1 Score): {f1:.4f}\")\n",
        "# print(f\"AUC 점수 (ROC AUC): {roc_auc:.4f}\")\n",
        "\n",
        "# 7. 예측 결과를 새로운 엑셀 파일로 저장\n",
        "test_data.to_excel('예측결과_보호구역설치.xlsx', index=False)\n",
        "\n",
        "# 완료 메시지 출력\n",
        "print(\"예측 결과와 보호구역 설치 여부가 '예측결과_보호구역설치.xlsx' 파일로 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "e_BPsm5y56LB",
        "outputId": "32218555-398a-423c-fa13-bda843cddd14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "id": "e_BPsm5y56LB",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [4267, 710]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-925d14818e1c>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 성능 지표 계산 (만약 실제 종속값이 있다면 사용)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# precision = precision_score(y_true, y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# recall = recall_score(y_true, y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace_and_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \"\"\"\n\u001b[1;32m    102\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4267, 710]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.columns)\n",
        "print(train_data.columns)"
      ],
      "metadata": {
        "id": "VEd6jeLCyd_N",
        "outputId": "bb05c9d1-5af4-4e46-f0a7-fcef2f98f597",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VEd6jeLCyd_N",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['시간단위', '격자명', '인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수',\n",
            "       'EPDO', '사고수', 'EPDO 정규화', '사고수 정규화', '종속변수', '종속', '위험도', '설치 여부',\n",
            "       '실효성 미비'],\n",
            "      dtype='object')\n",
            "Index(['시간단위', '격자명', '인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수',\n",
            "       'EPDO', '사고수', 'EPDO 정규화', '사고수 정규화', '종속변수', '종속', 'Unnamed: 13',\n",
            "       'EPDO.1', '사고수.1'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실행"
      ],
      "metadata": {
        "id": "JPTNvgjXdI-E"
      },
      "id": "JPTNvgjXdI-E"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "train_path = '/content/drive/MyDrive/노인보호구역 프로젝트/p프_전체계획.xlsx'\n",
        "test_path = '/content/drive/MyDrive/노인보호구역 프로젝트/TEST DATA.xlsx'\n",
        "\n",
        "train_data = pd.read_excel(train_path)\n",
        "test_data = pd.read_excel(test_path)\n",
        "\n",
        "\n",
        "# 학습할 데이터 준비\n",
        "predictor = TabularPredictor(label='종속').fit(train_data)\n",
        "\n",
        "\n",
        "# 독립변수 열 목록\n",
        "independent_vars = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 독립변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=independent_vars)\n",
        "\n",
        "# 종속변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=[target] + independent_vars)\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 2. 학습 데이터 준비\n",
        "target = '종속'\n",
        "features = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 3. AutoGluon 모델 학습\n",
        "predictor = TabularPredictor(label=target).fit(train_data[features + [target]])\n",
        "\n",
        "# 4. 위험도 예측\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 5. Top 5% 위험도를 가진 격자 추출\n",
        "top_5_percent_threshold = test_data['위험도'].quantile(0.95)\n",
        "test_data['보호구역 설치 여부'] = test_data['위험도'].apply(\n",
        "    lambda x: '예' if x >= top_5_percent_threshold else '아니오'\n",
        ")\n",
        "\n",
        "# 6. 결과 저장\n",
        "output_path = 'TEST_RESULT.xlsx'\n",
        "test_data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"결과 파일이 저장되었습니다: {output_path}\")"
      ],
      "metadata": {
        "id": "AbEQ55pN2sjj",
        "outputId": "334220e5-1c39-4ff2-fe19-77dbde4e3e62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AbEQ55pN2sjj",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_124216\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.80 GB / 12.67 GB (85.2%)\n",
            "Disk Space Avail:   71.13 GB / 107.72 GB (66.0%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_124216\"\n",
            "Train Data Rows:    3555\n",
            "Train Data Columns: 15\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.71893, 14.43737)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11055.06 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.90 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['Unnamed: 13']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t\t('object', []) :  2 | ['시간단위', '격자명']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['시간단위', '격자명']\n",
            "\t\t('float', [])    : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.27s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14064697609001406, Train Rows: 3055, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-3.8241\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-3.3703\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.907638\n",
            "[2000]\tvalid_set's rmse: 0.756411\n",
            "[3000]\tvalid_set's rmse: 0.691405\n",
            "[4000]\tvalid_set's rmse: 0.655507\n",
            "[5000]\tvalid_set's rmse: 0.629133\n",
            "[6000]\tvalid_set's rmse: 0.611962\n",
            "[7000]\tvalid_set's rmse: 0.599261\n",
            "[8000]\tvalid_set's rmse: 0.591129\n",
            "[9000]\tvalid_set's rmse: 0.584345\n",
            "[10000]\tvalid_set's rmse: 0.579338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5793\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.22s\t = Training   runtime\n",
            "\t2.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.559353\n",
            "[2000]\tvalid_set's rmse: 0.535635\n",
            "[3000]\tvalid_set's rmse: 0.525488\n",
            "[4000]\tvalid_set's rmse: 0.522953\n",
            "[5000]\tvalid_set's rmse: 0.521307\n",
            "[6000]\tvalid_set's rmse: 0.520564\n",
            "[7000]\tvalid_set's rmse: 0.520097\n",
            "[8000]\tvalid_set's rmse: 0.519679\n",
            "[9000]\tvalid_set's rmse: 0.519679\n",
            "[10000]\tvalid_set's rmse: 0.519756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5196\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.03s\t = Training   runtime\n",
            "\t1.38s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3125\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.84s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3029\t = Validation score   (-root_mean_squared_error)\n",
            "\t78.76s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3357\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.37s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2878\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.86s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.2766\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.17s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-1.0899\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.22s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.274246\n",
            "[2000]\tvalid_set's rmse: 0.270477\n",
            "[3000]\tvalid_set's rmse: 0.270048\n",
            "[4000]\tvalid_set's rmse: 0.269994\n",
            "[5000]\tvalid_set's rmse: 0.269982\n",
            "[6000]\tvalid_set's rmse: 0.26998\n",
            "[7000]\tvalid_set's rmse: 0.269979\n",
            "[8000]\tvalid_set's rmse: 0.269979\n",
            "[9000]\tvalid_set's rmse: 0.269979\n",
            "[10000]\tvalid_set's rmse: 0.269979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.27\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.28s\t = Training   runtime\n",
            "\t4.7s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.4, 'XGBoost': 0.35, 'LightGBMLarge': 0.15, 'CatBoost': 0.05, 'ExtraTreesMSE': 0.05}\n",
            "\t-0.2018\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 200.47s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 102.9 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_124216\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_124536\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.85 GB / 12.67 GB (85.6%)\n",
            "Disk Space Avail:   70.91 GB / 107.72 GB (65.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_124536\"\n",
            "Train Data Rows:    3550\n",
            "Train Data Columns: 5\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.8, 14.73966, 14.43695)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11109.10 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.14 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 5 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 5 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\t0.1s = Fit runtime\n",
            "\t5 features in original data used to generate 5 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.14 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n",
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatically generating train/validation split with holdout_frac=0.14084507042253522, Train Rows: 3050, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-16.4171\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-16.548\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 14.083\n",
            "[2000]\tvalid_set's rmse: 14.0096\n",
            "[3000]\tvalid_set's rmse: 14.0186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-13.9951\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.78s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 13.7511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-13.7227\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.06s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-13.5934\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.26s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-13.6655\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.67s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-13.4265\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.29s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-14.2688\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.44s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-13.9215\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.61s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-14.0494\t = Validation score   (-root_mean_squared_error)\n",
            "\t191.63s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-13.3911\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.85s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'ExtraTreesMSE': 0.476, 'LightGBMLarge': 0.286, 'NeuralNetFastAI': 0.143, 'NeuralNetTorch': 0.095}\n",
            "\t-13.122\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 211.14s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3300.3 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_124536\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결과 파일이 저장되었습니다: TEST_RESULT.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 실제값과 예측값 계산\n",
        "y_true = train_data[target]\n",
        "y_pred = predictor.predict(train_data[features])\n",
        "\n",
        "# 지표 수동 계산\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\n=== 성능 지표 ===\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "id": "VIMqnmbzhEKv"
      },
      "id": "VIMqnmbzhEKv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "보호구역 개수를 제외한 모델"
      ],
      "metadata": {
        "id": "18CxAtPzg7-J"
      },
      "id": "18CxAtPzg7-J"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "train_path = '/content/drive/MyDrive/노인보호구역 프로젝트/p프_전체계획.xlsx'\n",
        "test_path = '/content/drive/MyDrive/노인보호구역 프로젝트/TEST DATA.xlsx'\n",
        "\n",
        "train_data = pd.read_excel(train_path)\n",
        "test_data = pd.read_excel(test_path)\n",
        "\n",
        "\n",
        "# 학습할 데이터 준비\n",
        "predictor = TabularPredictor(label='종속').fit(train_data)\n",
        "\n",
        "\n",
        "# 독립변수 열 목록\n",
        "independent_vars = ['인구수', '경로당 수', '복지시설 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 독립변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=independent_vars)\n",
        "\n",
        "# 종속변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=[target] + independent_vars)\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 2. 학습 데이터 준비\n",
        "target = '종속'\n",
        "features = ['인구수', '경로당 수', '복지시설 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 3. AutoGluon 모델 학습\n",
        "predictor = TabularPredictor(label=target).fit(train_data[features + [target]])\n",
        "\n",
        "# 4. 위험도 예측\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 5. Top 5% 위험도를 가진 격자 추출\n",
        "top_5_percent_threshold = test_data['위험도'].quantile(0.95)\n",
        "test_data['보호구역 설치 여부'] = test_data['위험도'].apply(\n",
        "    lambda x: '예' if x >= top_5_percent_threshold else '아니오'\n",
        ")\n",
        "\n",
        "# 6. 결과 저장\n",
        "output_path = 'TEST_RESULT_보호구역제외.xlsx'\n",
        "test_data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"결과 파일이 저장되었습니다: {output_path}\")"
      ],
      "metadata": {
        "id": "9LrvhUakg1uW",
        "outputId": "0ee8a9c1-4d67-40ac-fda8-ff1bc17cd768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9LrvhUakg1uW",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_130427\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.83 GB / 12.67 GB (85.5%)\n",
            "Disk Space Avail:   70.76 GB / 107.72 GB (65.7%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_130427\"\n",
            "Train Data Rows:    3555\n",
            "Train Data Columns: 15\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.71893, 14.43737)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11093.97 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.90 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['Unnamed: 13']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t\t('object', []) :  2 | ['시간단위', '격자명']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['시간단위', '격자명']\n",
            "\t\t('float', [])    : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t0.3s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.3s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14064697609001406, Train Rows: 3055, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-3.8241\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-3.3703\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.907638\n",
            "[2000]\tvalid_set's rmse: 0.756411\n",
            "[3000]\tvalid_set's rmse: 0.691405\n",
            "[4000]\tvalid_set's rmse: 0.655507\n",
            "[5000]\tvalid_set's rmse: 0.629133\n",
            "[6000]\tvalid_set's rmse: 0.611962\n",
            "[7000]\tvalid_set's rmse: 0.599261\n",
            "[8000]\tvalid_set's rmse: 0.591129\n",
            "[9000]\tvalid_set's rmse: 0.584345\n",
            "[10000]\tvalid_set's rmse: 0.579338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5793\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.34s\t = Training   runtime\n",
            "\t1.81s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.559353\n",
            "[2000]\tvalid_set's rmse: 0.535635\n",
            "[3000]\tvalid_set's rmse: 0.525488\n",
            "[4000]\tvalid_set's rmse: 0.522953\n",
            "[5000]\tvalid_set's rmse: 0.521307\n",
            "[6000]\tvalid_set's rmse: 0.520564\n",
            "[7000]\tvalid_set's rmse: 0.520097\n",
            "[8000]\tvalid_set's rmse: 0.519679\n",
            "[9000]\tvalid_set's rmse: 0.519679\n",
            "[10000]\tvalid_set's rmse: 0.519756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5196\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.11s\t = Training   runtime\n",
            "\t1.36s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3125\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.87s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3029\t = Validation score   (-root_mean_squared_error)\n",
            "\t79.1s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3357\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.37s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2878\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.97s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.2766\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.55s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-1.0899\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.34s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.274246\n",
            "[2000]\tvalid_set's rmse: 0.270477\n",
            "[3000]\tvalid_set's rmse: 0.270048\n",
            "[4000]\tvalid_set's rmse: 0.269994\n",
            "[5000]\tvalid_set's rmse: 0.269982\n",
            "[6000]\tvalid_set's rmse: 0.26998\n",
            "[7000]\tvalid_set's rmse: 0.269979\n",
            "[8000]\tvalid_set's rmse: 0.269979\n",
            "[9000]\tvalid_set's rmse: 0.269979\n",
            "[10000]\tvalid_set's rmse: 0.269979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.27\t = Validation score   (-root_mean_squared_error)\n",
            "\t44.58s\t = Training   runtime\n",
            "\t3.02s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.4, 'XGBoost': 0.35, 'LightGBMLarge': 0.15, 'CatBoost': 0.05, 'ExtraTreesMSE': 0.05}\n",
            "\t-0.2018\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 197.54s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 156.4 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_130427\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_130744\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.86 GB / 12.67 GB (85.7%)\n",
            "Disk Space Avail:   70.53 GB / 107.72 GB (65.5%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_130744\"\n",
            "Train Data Rows:    3550\n",
            "Train Data Columns: 4\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.8, 14.73966, 14.43695)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11122.24 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['인구수', '경로당 수', '복지시설 개수', '과속단속카메라 개수']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['인구수', '경로당 수', '복지시설 개수', '과속단속카메라 개수']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14084507042253522, Train Rows: 3050, Val Rows: 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n",
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-16.3212\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-16.4726\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 14.244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-14.237\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.13s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-14.0042\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-13.9419\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.21s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-13.7916\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.89s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-13.7028\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.26s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-14.4046\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.16s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-14.0218\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.63s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-14.6263\t = Validation score   (-root_mean_squared_error)\n",
            "\t18.79s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-13.5659\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'ExtraTreesMSE': 0.455, 'LightGBMLarge': 0.364, 'NeuralNetFastAI': 0.182}\n",
            "\t-13.3435\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 35.14s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3703.5 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_130744\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결과 파일이 저장되었습니다: TEST_RESULT_보호구역제외.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 실제값과 예측값 계산\n",
        "y_true = train_data[target]\n",
        "y_pred = predictor.predict(train_data[features])\n",
        "\n",
        "# 지표 수동 계산\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\n=== 성능 지표 ===\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "id": "kf2bV3d1h4HM",
        "outputId": "df069a3c-0495-4f80-99f7-394a368dc140",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kf2bV3d1h4HM",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 성능 지표 ===\n",
            "Mean Squared Error: 78.21077803694665\n",
            "Mean Absolute Error: 6.258742185619516\n",
            "R^2 Score: 0.6246488133598922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "인구수 제외 모델"
      ],
      "metadata": {
        "id": "YA6Wjh5Ej4Jq"
      },
      "id": "YA6Wjh5Ej4Jq"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "train_path = '/content/drive/MyDrive/노인보호구역 프로젝트/p프_전체계획.xlsx'\n",
        "test_path = '/content/drive/MyDrive/노인보호구역 프로젝트/TEST DATA.xlsx'\n",
        "\n",
        "train_data = pd.read_excel(train_path)\n",
        "test_data = pd.read_excel(test_path)\n",
        "\n",
        "\n",
        "# 학습할 데이터 준비\n",
        "predictor = TabularPredictor(label='종속').fit(train_data)\n",
        "\n",
        "\n",
        "# 독립변수 열 목록\n",
        "independent_vars = [ '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 독립변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=independent_vars)\n",
        "\n",
        "# 종속변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=[target] + independent_vars)\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 2. 학습 데이터 준비\n",
        "target = '종속'\n",
        "features = ['경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 3. AutoGluon 모델 학습\n",
        "predictor = TabularPredictor(label=target).fit(train_data[features + [target]])\n",
        "\n",
        "# 4. 위험도 예측\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 5. Top 5% 위험도를 가진 격자 추출\n",
        "top_5_percent_threshold = test_data['위험도'].quantile(0.95)\n",
        "test_data['보호구역 설치 여부'] = test_data['위험도'].apply(\n",
        "    lambda x: '예' if x >= top_5_percent_threshold else '아니오'\n",
        ")\n",
        "\n",
        "# 6. 결과 저장\n",
        "output_path = 'TEST_RESULT_인구수제외.xlsx'\n",
        "test_data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"결과 파일이 저장되었습니다: {output_path}\")"
      ],
      "metadata": {
        "id": "bcqM9JNbj-TX",
        "outputId": "9a931e3a-c29d-4442-aaa5-b11f562bccc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bcqM9JNbj-TX",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_131701\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.84 GB / 12.67 GB (85.5%)\n",
            "Disk Space Avail:   70.39 GB / 107.72 GB (65.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_131701\"\n",
            "Train Data Rows:    3555\n",
            "Train Data Columns: 15\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.71893, 14.43737)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11096.08 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.90 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['Unnamed: 13']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t\t('object', []) :  2 | ['시간단위', '격자명']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['시간단위', '격자명']\n",
            "\t\t('float', [])    : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t0.3s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.33s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14064697609001406, Train Rows: 3055, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-3.8241\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-3.3703\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.907638\n",
            "[2000]\tvalid_set's rmse: 0.756411\n",
            "[3000]\tvalid_set's rmse: 0.691405\n",
            "[4000]\tvalid_set's rmse: 0.655507\n",
            "[5000]\tvalid_set's rmse: 0.629133\n",
            "[6000]\tvalid_set's rmse: 0.611962\n",
            "[7000]\tvalid_set's rmse: 0.599261\n",
            "[8000]\tvalid_set's rmse: 0.591129\n",
            "[9000]\tvalid_set's rmse: 0.584345\n",
            "[10000]\tvalid_set's rmse: 0.579338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5793\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.55s\t = Training   runtime\n",
            "\t1.59s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.559353\n",
            "[2000]\tvalid_set's rmse: 0.535635\n",
            "[3000]\tvalid_set's rmse: 0.525488\n",
            "[4000]\tvalid_set's rmse: 0.522953\n",
            "[5000]\tvalid_set's rmse: 0.521307\n",
            "[6000]\tvalid_set's rmse: 0.520564\n",
            "[7000]\tvalid_set's rmse: 0.520097\n",
            "[8000]\tvalid_set's rmse: 0.519679\n",
            "[9000]\tvalid_set's rmse: 0.519679\n",
            "[10000]\tvalid_set's rmse: 0.519756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5196\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.15s\t = Training   runtime\n",
            "\t1.41s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3125\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.9s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3029\t = Validation score   (-root_mean_squared_error)\n",
            "\t78.88s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3357\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.37s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2878\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.06s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.2766\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.87s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-1.0899\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.29s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.274246\n",
            "[2000]\tvalid_set's rmse: 0.270477\n",
            "[3000]\tvalid_set's rmse: 0.270048\n",
            "[4000]\tvalid_set's rmse: 0.269994\n",
            "[5000]\tvalid_set's rmse: 0.269982\n",
            "[6000]\tvalid_set's rmse: 0.26998\n",
            "[7000]\tvalid_set's rmse: 0.269979\n",
            "[8000]\tvalid_set's rmse: 0.269979\n",
            "[9000]\tvalid_set's rmse: 0.269979\n",
            "[10000]\tvalid_set's rmse: 0.269979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.27\t = Validation score   (-root_mean_squared_error)\n",
            "\t44.04s\t = Training   runtime\n",
            "\t3.88s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.4, 'XGBoost': 0.35, 'LightGBMLarge': 0.15, 'CatBoost': 0.05, 'ExtraTreesMSE': 0.05}\n",
            "\t-0.2018\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 206.59s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 123.3 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_131701\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_132028\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.87 GB / 12.67 GB (85.8%)\n",
            "Disk Space Avail:   70.16 GB / 107.72 GB (65.1%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_132028\"\n",
            "Train Data Rows:    3550\n",
            "Train Data Columns: 4\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.8, 14.73966, 14.43695)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11131.44 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14084507042253522, Train Rows: 3050, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n",
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-15.4675\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-15.2768\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 14.4574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-14.457\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-14.3744\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.49s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-14.4059\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.98s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-14.3674\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.58s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-14.3747\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.88s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-14.511\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-14.5327\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.63s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-14.6698\t = Validation score   (-root_mean_squared_error)\n",
            "\t38.06s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-14.3305\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.76s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'ExtraTreesMSE': 0.375, 'NeuralNetFastAI': 0.292, 'LightGBMLarge': 0.167, 'RandomForestMSE': 0.083, 'CatBoost': 0.042, 'NeuralNetTorch': 0.042}\n",
            "\t-14.2222\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 48.11s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1938.7 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_132028\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결과 파일이 저장되었습니다: TEST_RESULT_인구수제외.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 실제값과 예측값 계산\n",
        "y_true = train_data[target]\n",
        "y_pred = predictor.predict(train_data[features])\n",
        "\n",
        "# 지표 수동 계산\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\n=== 성능 지표 ===\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "id": "63w-vMQ9kQ9j",
        "outputId": "7a39e974-a226-49b2-f5e3-10bdfc76b415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "63w-vMQ9kQ9j",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 성능 지표 ===\n",
            "Mean Squared Error: 149.22603838848684\n",
            "Mean Absolute Error: 8.92971920206849\n",
            "R^2 Score: 0.283830541101883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "경로당 수 제외 모델"
      ],
      "metadata": {
        "id": "Sixm9c8VlUlW"
      },
      "id": "Sixm9c8VlUlW"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "train_path = '/content/drive/MyDrive/노인보호구역 프로젝트/p프_전체계획.xlsx'\n",
        "test_path = '/content/drive/MyDrive/노인보호구역 프로젝트/TEST DATA.xlsx'\n",
        "\n",
        "train_data = pd.read_excel(train_path)\n",
        "test_data = pd.read_excel(test_path)\n",
        "\n",
        "\n",
        "# 학습할 데이터 준비\n",
        "predictor = TabularPredictor(label='종속').fit(train_data)\n",
        "\n",
        "\n",
        "# 독립변수 열 목록\n",
        "independent_vars = ['인구수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 독립변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=independent_vars)\n",
        "\n",
        "# 종속변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=[target] + independent_vars)\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 2. 학습 데이터 준비\n",
        "target = '종속'\n",
        "features = ['인구수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 3. AutoGluon 모델 학습\n",
        "predictor = TabularPredictor(label=target).fit(train_data[features + [target]])\n",
        "\n",
        "# 4. 위험도 예측\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 5. Top 5% 위험도를 가진 격자 추출\n",
        "top_5_percent_threshold = test_data['위험도'].quantile(0.95)\n",
        "test_data['보호구역 설치 여부'] = test_data['위험도'].apply(\n",
        "    lambda x: '예' if x >= top_5_percent_threshold else '아니오'\n",
        ")\n",
        "\n",
        "# 6. 결과 저장\n",
        "output_path = 'TEST_RESULT_경로당제외.xlsx'\n",
        "test_data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"결과 파일이 저장되었습니다: {output_path}\")"
      ],
      "metadata": {
        "id": "N9xUCurVldhJ",
        "outputId": "44851e63-5ad6-436e-aa9f-349824628f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "N9xUCurVldhJ",
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_132248\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.84 GB / 12.67 GB (85.5%)\n",
            "Disk Space Avail:   70.13 GB / 107.72 GB (65.1%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_132248\"\n",
            "Train Data Rows:    3555\n",
            "Train Data Columns: 15\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.71893, 14.43737)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11103.13 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.90 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['Unnamed: 13']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t\t('object', []) :  2 | ['시간단위', '격자명']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['시간단위', '격자명']\n",
            "\t\t('float', [])    : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t0.3s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.34s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14064697609001406, Train Rows: 3055, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-3.8241\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-3.3703\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.907638\n",
            "[2000]\tvalid_set's rmse: 0.756411\n",
            "[3000]\tvalid_set's rmse: 0.691405\n",
            "[4000]\tvalid_set's rmse: 0.655507\n",
            "[5000]\tvalid_set's rmse: 0.629133\n",
            "[6000]\tvalid_set's rmse: 0.611962\n",
            "[7000]\tvalid_set's rmse: 0.599261\n",
            "[8000]\tvalid_set's rmse: 0.591129\n",
            "[9000]\tvalid_set's rmse: 0.584345\n",
            "[10000]\tvalid_set's rmse: 0.579338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5793\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.0s\t = Training   runtime\n",
            "\t1.56s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.559353\n",
            "[2000]\tvalid_set's rmse: 0.535635\n",
            "[3000]\tvalid_set's rmse: 0.525488\n",
            "[4000]\tvalid_set's rmse: 0.522953\n",
            "[5000]\tvalid_set's rmse: 0.521307\n",
            "[6000]\tvalid_set's rmse: 0.520564\n",
            "[7000]\tvalid_set's rmse: 0.520097\n",
            "[8000]\tvalid_set's rmse: 0.519679\n",
            "[9000]\tvalid_set's rmse: 0.519679\n",
            "[10000]\tvalid_set's rmse: 0.519756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5196\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.55s\t = Training   runtime\n",
            "\t1.62s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3125\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.87s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3029\t = Validation score   (-root_mean_squared_error)\n",
            "\t77.78s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3357\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.93s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2878\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.71s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.2766\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.17s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-1.0899\t = Validation score   (-root_mean_squared_error)\n",
            "\t18.45s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.274246\n",
            "[2000]\tvalid_set's rmse: 0.270477\n",
            "[3000]\tvalid_set's rmse: 0.270048\n",
            "[4000]\tvalid_set's rmse: 0.269994\n",
            "[5000]\tvalid_set's rmse: 0.269982\n",
            "[6000]\tvalid_set's rmse: 0.26998\n",
            "[7000]\tvalid_set's rmse: 0.269979\n",
            "[8000]\tvalid_set's rmse: 0.269979\n",
            "[9000]\tvalid_set's rmse: 0.269979\n",
            "[10000]\tvalid_set's rmse: 0.269979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.27\t = Validation score   (-root_mean_squared_error)\n",
            "\t44.26s\t = Training   runtime\n",
            "\t3.12s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.4, 'XGBoost': 0.35, 'LightGBMLarge': 0.15, 'CatBoost': 0.05, 'ExtraTreesMSE': 0.05}\n",
            "\t-0.2018\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 199.07s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 152.6 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_132248\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_132608\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.87 GB / 12.67 GB (85.8%)\n",
            "Disk Space Avail:   69.90 GB / 107.72 GB (64.9%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_132608\"\n",
            "Train Data Rows:    3550\n",
            "Train Data Columns: 4\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.8, 14.73966, 14.43695)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11129.56 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['인구수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['인구수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14084507042253522, Train Rows: 3050, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n",
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-16.3862\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-17.114\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 14.6501\n",
            "[2000]\tvalid_set's rmse: 14.6036\n",
            "[3000]\tvalid_set's rmse: 14.5901\n",
            "[4000]\tvalid_set's rmse: 14.5878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-14.5761\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.13s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-14.6224\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.52s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-15.2554\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.18s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-14.5641\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.98s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-14.9911\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.29s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-14.7952\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.04s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-14.5968\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-15.4336\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.91s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-14.5708\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.78s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'ExtraTreesMSE': 0.381, 'NeuralNetFastAI': 0.333, 'XGBoost': 0.143, 'LightGBMLarge': 0.095, 'CatBoost': 0.048}\n",
            "\t-14.3286\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 20.67s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3066.8 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_132608\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결과 파일이 저장되었습니다: TEST_RESULT_경로당제외.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 실제값과 예측값 계산\n",
        "y_true = train_data[target]\n",
        "y_pred = predictor.predict(train_data[features])\n",
        "\n",
        "# 지표 수동 계산\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\n=== 성능 지표 ===\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "id": "E5JGr1P3mvxj",
        "outputId": "0ccf745a-a28f-4bcb-c08e-a9525ac0f304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "E5JGr1P3mvxj",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 성능 지표 ===\n",
            "Mean Squared Error: 109.01122578012615\n",
            "Mean Absolute Error: 7.688914768380179\n",
            "R^2 Score: 0.47683050877803945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "카메라 제외"
      ],
      "metadata": {
        "id": "jch06IhKm72Q"
      },
      "id": "jch06IhKm72Q"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "train_path = '/content/drive/MyDrive/노인보호구역 프로젝트/p프_전체계획.xlsx'\n",
        "test_path = '/content/drive/MyDrive/노인보호구역 프로젝트/TEST DATA.xlsx'\n",
        "\n",
        "train_data = pd.read_excel(train_path)\n",
        "test_data = pd.read_excel(test_path)\n",
        "\n",
        "\n",
        "# 학습할 데이터 준비\n",
        "predictor = TabularPredictor(label='종속').fit(train_data)\n",
        "\n",
        "\n",
        "# 독립변수 열 목록\n",
        "independent_vars = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수']\n",
        "\n",
        "# 독립변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=independent_vars)\n",
        "\n",
        "# 종속변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=[target] + independent_vars)\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 2. 학습 데이터 준비\n",
        "target = '종속'\n",
        "features = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수']\n",
        "\n",
        "# 3. AutoGluon 모델 학습\n",
        "predictor = TabularPredictor(label=target).fit(train_data[features + [target]])\n",
        "\n",
        "# 4. 위험도 예측\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 5. Top 5% 위험도를 가진 격자 추출\n",
        "top_5_percent_threshold = test_data['위험도'].quantile(0.95)\n",
        "test_data['보호구역 설치 여부'] = test_data['위험도'].apply(\n",
        "    lambda x: '예' if x >= top_5_percent_threshold else '아니오'\n",
        ")\n",
        "\n",
        "# 6. 결과 저장\n",
        "output_path = 'TEST_RESULT_카메라제외.xlsx'\n",
        "test_data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"결과 파일이 저장되었습니다: {output_path}\")"
      ],
      "metadata": {
        "id": "t6ByGMism9Lp",
        "outputId": "c8552e38-dc5e-4c73-dcd2-978dc281d1fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "t6ByGMism9Lp",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_132940\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.81 GB / 12.67 GB (85.3%)\n",
            "Disk Space Avail:   69.76 GB / 107.72 GB (64.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_132940\"\n",
            "Train Data Rows:    3555\n",
            "Train Data Columns: 15\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.71893, 14.43737)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11075.20 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.90 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['Unnamed: 13']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t\t('object', []) :  2 | ['시간단위', '격자명']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['시간단위', '격자명']\n",
            "\t\t('float', [])    : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t0.3s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.33s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14064697609001406, Train Rows: 3055, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-3.8241\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-3.3703\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.907638\n",
            "[2000]\tvalid_set's rmse: 0.756411\n",
            "[3000]\tvalid_set's rmse: 0.691405\n",
            "[4000]\tvalid_set's rmse: 0.655507\n",
            "[5000]\tvalid_set's rmse: 0.629133\n",
            "[6000]\tvalid_set's rmse: 0.611962\n",
            "[7000]\tvalid_set's rmse: 0.599261\n",
            "[8000]\tvalid_set's rmse: 0.591129\n",
            "[9000]\tvalid_set's rmse: 0.584345\n",
            "[10000]\tvalid_set's rmse: 0.579338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5793\t = Validation score   (-root_mean_squared_error)\n",
            "\t12.04s\t = Training   runtime\n",
            "\t1.6s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.559353\n",
            "[2000]\tvalid_set's rmse: 0.535635\n",
            "[3000]\tvalid_set's rmse: 0.525488\n",
            "[4000]\tvalid_set's rmse: 0.522953\n",
            "[5000]\tvalid_set's rmse: 0.521307\n",
            "[6000]\tvalid_set's rmse: 0.520564\n",
            "[7000]\tvalid_set's rmse: 0.520097\n",
            "[8000]\tvalid_set's rmse: 0.519679\n",
            "[9000]\tvalid_set's rmse: 0.519679\n",
            "[10000]\tvalid_set's rmse: 0.519756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5196\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.27s\t = Training   runtime\n",
            "\t1.76s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3125\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.99s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3029\t = Validation score   (-root_mean_squared_error)\n",
            "\t82.52s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3357\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.48s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2878\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.85s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.2766\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.17s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-1.0899\t = Validation score   (-root_mean_squared_error)\n",
            "\t18.33s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.274246\n",
            "[2000]\tvalid_set's rmse: 0.270477\n",
            "[3000]\tvalid_set's rmse: 0.270048\n",
            "[4000]\tvalid_set's rmse: 0.269994\n",
            "[5000]\tvalid_set's rmse: 0.269982\n",
            "[6000]\tvalid_set's rmse: 0.26998\n",
            "[7000]\tvalid_set's rmse: 0.269979\n",
            "[8000]\tvalid_set's rmse: 0.269979\n",
            "[9000]\tvalid_set's rmse: 0.269979\n",
            "[10000]\tvalid_set's rmse: 0.269979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.27\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.82s\t = Training   runtime\n",
            "\t3.77s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.4, 'XGBoost': 0.35, 'LightGBMLarge': 0.15, 'CatBoost': 0.05, 'ExtraTreesMSE': 0.05}\n",
            "\t-0.2018\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 202.97s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 126.6 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_132940\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_133303\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.85 GB / 12.67 GB (85.6%)\n",
            "Disk Space Avail:   69.53 GB / 107.72 GB (64.5%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_133303\"\n",
            "Train Data Rows:    3550\n",
            "Train Data Columns: 4\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.8, 14.73966, 14.43695)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11109.60 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14084507042253522, Train Rows: 3050, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n",
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-16.4105\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-16.6747\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-14.5295\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.63s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-14.3325\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-14.8017\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.06s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-14.239\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.72s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-14.466\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.57s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-14.6129\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.1s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-14.4431\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-14.8975\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.33s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-14.0533\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.8s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBMLarge': 0.435, 'ExtraTreesMSE': 0.348, 'NeuralNetFastAI': 0.217}\n",
            "\t-13.9181\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 26.17s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3696.5 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_133303\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결과 파일이 저장되었습니다: TEST_RESULT_카메라제외.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 실제값과 예측값 계산\n",
        "y_true = train_data[target]\n",
        "y_pred = predictor.predict(train_data[features])\n",
        "\n",
        "# 지표 수동 계산\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\n=== 성능 지표 ===\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "id": "SJiNtpJ_nI4E",
        "outputId": "48ad0cd0-2485-4c0d-8084-c78fd5f7993c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SJiNtpJ_nI4E",
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 성능 지표 ===\n",
            "Mean Squared Error: 104.61353762450382\n",
            "Mean Absolute Error: 7.532573120372397\n",
            "R^2 Score: 0.49793600739494637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "복지시설, 보호구역 제외"
      ],
      "metadata": {
        "id": "oBikUR6goml8"
      },
      "id": "oBikUR6goml8"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "train_path = '/content/drive/MyDrive/노인보호구역 프로젝트/p프_전체계획.xlsx'\n",
        "test_path = '/content/drive/MyDrive/노인보호구역 프로젝트/TEST DATA.xlsx'\n",
        "\n",
        "train_data = pd.read_excel(train_path)\n",
        "test_data = pd.read_excel(test_path)\n",
        "\n",
        "\n",
        "# 학습할 데이터 준비\n",
        "predictor = TabularPredictor(label='종속').fit(train_data)\n",
        "\n",
        "\n",
        "# 독립변수 열 목록\n",
        "independent_vars = ['인구수', '경로당 수','과속단속카메라 개수']\n",
        "\n",
        "# 독립변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=independent_vars)\n",
        "\n",
        "# 종속변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=[target] + independent_vars)\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 2. 학습 데이터 준비\n",
        "target = '종속'\n",
        "features = ['인구수', '경로당 수', '과속단속카메라 개수']\n",
        "\n",
        "# 3. AutoGluon 모델 학습\n",
        "predictor = TabularPredictor(label=target).fit(train_data[features + [target]])\n",
        "\n",
        "# 4. 위험도 예측\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 5. Top 5% 위험도를 가진 격자 추출\n",
        "top_5_percent_threshold = test_data['위험도'].quantile(0.95)\n",
        "test_data['보호구역 설치 여부'] = test_data['위험도'].apply(\n",
        "    lambda x: '예' if x >= top_5_percent_threshold else '아니오'\n",
        ")\n",
        "\n",
        "# 6. 결과 저장\n",
        "output_path = 'TEST_RESULT_복지보호제외.xlsx'\n",
        "test_data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"결과 파일이 저장되었습니다: {output_path}\")"
      ],
      "metadata": {
        "id": "NJ0TZF4Qoo4z",
        "outputId": "88bbdd59-43a8-430d-ea0a-a6cfd40889d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NJ0TZF4Qoo4z",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_133658\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.80 GB / 12.67 GB (85.2%)\n",
            "Disk Space Avail:   69.39 GB / 107.72 GB (64.4%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_133658\"\n",
            "Train Data Rows:    3555\n",
            "Train Data Columns: 15\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.71893, 14.43737)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11061.10 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.90 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['Unnamed: 13']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t\t('object', []) :  2 | ['시간단위', '격자명']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['시간단위', '격자명']\n",
            "\t\t('float', [])    : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t0.3s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.33s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14064697609001406, Train Rows: 3055, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-3.8241\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-3.3703\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.907638\n",
            "[2000]\tvalid_set's rmse: 0.756411\n",
            "[3000]\tvalid_set's rmse: 0.691405\n",
            "[4000]\tvalid_set's rmse: 0.655507\n",
            "[5000]\tvalid_set's rmse: 0.629133\n",
            "[6000]\tvalid_set's rmse: 0.611962\n",
            "[7000]\tvalid_set's rmse: 0.599261\n",
            "[8000]\tvalid_set's rmse: 0.591129\n",
            "[9000]\tvalid_set's rmse: 0.584345\n",
            "[10000]\tvalid_set's rmse: 0.579338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5793\t = Validation score   (-root_mean_squared_error)\n",
            "\t11.28s\t = Training   runtime\n",
            "\t1.58s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.559353\n",
            "[2000]\tvalid_set's rmse: 0.535635\n",
            "[3000]\tvalid_set's rmse: 0.525488\n",
            "[4000]\tvalid_set's rmse: 0.522953\n",
            "[5000]\tvalid_set's rmse: 0.521307\n",
            "[6000]\tvalid_set's rmse: 0.520564\n",
            "[7000]\tvalid_set's rmse: 0.520097\n",
            "[8000]\tvalid_set's rmse: 0.519679\n",
            "[9000]\tvalid_set's rmse: 0.519679\n",
            "[10000]\tvalid_set's rmse: 0.519756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5196\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.47s\t = Training   runtime\n",
            "\t1.69s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3125\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.18s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3029\t = Validation score   (-root_mean_squared_error)\n",
            "\t78.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3357\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.48s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2878\t = Validation score   (-root_mean_squared_error)\n",
            "\t6.24s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.2766\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.17s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-1.0899\t = Validation score   (-root_mean_squared_error)\n",
            "\t17.92s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.274246\n",
            "[2000]\tvalid_set's rmse: 0.270477\n",
            "[3000]\tvalid_set's rmse: 0.270048\n",
            "[4000]\tvalid_set's rmse: 0.269994\n",
            "[5000]\tvalid_set's rmse: 0.269982\n",
            "[6000]\tvalid_set's rmse: 0.26998\n",
            "[7000]\tvalid_set's rmse: 0.269979\n",
            "[8000]\tvalid_set's rmse: 0.269979\n",
            "[9000]\tvalid_set's rmse: 0.269979\n",
            "[10000]\tvalid_set's rmse: 0.269979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.27\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.99s\t = Training   runtime\n",
            "\t2.99s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.4, 'XGBoost': 0.35, 'LightGBMLarge': 0.15, 'CatBoost': 0.05, 'ExtraTreesMSE': 0.05}\n",
            "\t-0.2018\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 199.09s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 158.4 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_133658\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_134017\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.85 GB / 12.67 GB (85.6%)\n",
            "Disk Space Avail:   69.16 GB / 107.72 GB (64.2%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_134017\"\n",
            "Train Data Rows:    3550\n",
            "Train Data Columns: 3\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.8, 14.73966, 14.43695)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11106.18 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 3 | ['인구수', '경로당 수', '과속단속카메라 개수']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 3 | ['인구수', '경로당 수', '과속단속카메라 개수']\n",
            "\t0.1s = Fit runtime\n",
            "\t3 features in original data used to generate 3 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.08 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14084507042253522, Train Rows: 3050, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n",
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-16.3286\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-16.5287\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-14.3326\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.61s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-14.1783\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-14.5527\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.03s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-14.2033\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-14.3447\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.23s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-14.4298\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.4s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-14.1082\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-14.6595\t = Validation score   (-root_mean_squared_error)\n",
            "\t30.58s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-13.8738\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.1s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBMLarge': 0.409, 'ExtraTreesMSE': 0.318, 'NeuralNetFastAI': 0.273}\n",
            "\t-13.7199\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 43.72s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3601.2 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_134017\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결과 파일이 저장되었습니다: TEST_RESULT_복지보호제외.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 실제값과 예측값 계산\n",
        "y_true = train_data[target]\n",
        "y_pred = predictor.predict(train_data[features])\n",
        "\n",
        "# 지표 수동 계산\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\n=== 성능 지표 ===\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "id": "AQzNi1OIoz8l",
        "outputId": "878dd5b5-d7c8-450a-c342-fdd78d9e083d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AQzNi1OIoz8l",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 성능 지표 ===\n",
            "Mean Squared Error: 95.63962622528018\n",
            "Mean Absolute Error: 7.07646304102347\n",
            "R^2 Score: 0.5410038348356934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 상위 1%"
      ],
      "metadata": {
        "id": "50YgCZo1qpHq"
      },
      "id": "50YgCZo1qpHq"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "train_path = '/content/drive/MyDrive/노인보호구역 프로젝트/p프_전체계획.xlsx'\n",
        "test_path = '/content/drive/MyDrive/노인보호구역 프로젝트/TEST DATA.xlsx'\n",
        "\n",
        "train_data = pd.read_excel(train_path)\n",
        "test_data = pd.read_excel(test_path)\n",
        "\n",
        "\n",
        "# 학습할 데이터 준비\n",
        "predictor = TabularPredictor(label='종속').fit(train_data)\n",
        "\n",
        "\n",
        "# 독립변수 열 목록\n",
        "independent_vars = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 독립변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=independent_vars)\n",
        "\n",
        "# 종속변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=[target] + independent_vars)\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 2. 학습 데이터 준비\n",
        "target = '종속'\n",
        "features = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 3. AutoGluon 모델 학습\n",
        "predictor = TabularPredictor(label=target).fit(train_data[features + [target]])\n",
        "\n",
        "# 4. 위험도 예측\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 5. Top 5% 위험도를 가진 격자 추출\n",
        "top_5_percent_threshold = test_data['위험도'].quantile(0.99)\n",
        "test_data['보호구역 설치 여부'] = test_data['위험도'].apply(\n",
        "    lambda x: '예' if x >= top_5_percent_threshold else '아니오'\n",
        ")\n",
        "\n",
        "# 6. 결과 저장\n",
        "output_path = 'TEST_RESULT_1%.xlsx'\n",
        "test_data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"결과 파일이 저장되었습니다: {output_path}\")"
      ],
      "metadata": {
        "id": "SuFeqUjKqsjQ",
        "outputId": "425d3f05-6c9d-4008-ccfc-67682f2f2910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SuFeqUjKqsjQ",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_134555\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.81 GB / 12.67 GB (85.3%)\n",
            "Disk Space Avail:   69.02 GB / 107.72 GB (64.1%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_134555\"\n",
            "Train Data Rows:    3555\n",
            "Train Data Columns: 15\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.71893, 14.43737)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11066.96 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.90 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['Unnamed: 13']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t\t('object', []) :  2 | ['시간단위', '격자명']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['시간단위', '격자명']\n",
            "\t\t('float', [])    : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t0.3s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.33s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14064697609001406, Train Rows: 3055, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-3.8241\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-3.3703\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.907638\n",
            "[2000]\tvalid_set's rmse: 0.756411\n",
            "[3000]\tvalid_set's rmse: 0.691405\n",
            "[4000]\tvalid_set's rmse: 0.655507\n",
            "[5000]\tvalid_set's rmse: 0.629133\n",
            "[6000]\tvalid_set's rmse: 0.611962\n",
            "[7000]\tvalid_set's rmse: 0.599261\n",
            "[8000]\tvalid_set's rmse: 0.591129\n",
            "[9000]\tvalid_set's rmse: 0.584345\n",
            "[10000]\tvalid_set's rmse: 0.579338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5793\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.91s\t = Training   runtime\n",
            "\t2.1s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.559353\n",
            "[2000]\tvalid_set's rmse: 0.535635\n",
            "[3000]\tvalid_set's rmse: 0.525488\n",
            "[4000]\tvalid_set's rmse: 0.522953\n",
            "[5000]\tvalid_set's rmse: 0.521307\n",
            "[6000]\tvalid_set's rmse: 0.520564\n",
            "[7000]\tvalid_set's rmse: 0.520097\n",
            "[8000]\tvalid_set's rmse: 0.519679\n",
            "[9000]\tvalid_set's rmse: 0.519679\n",
            "[10000]\tvalid_set's rmse: 0.519756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5196\t = Validation score   (-root_mean_squared_error)\n",
            "\t16.34s\t = Training   runtime\n",
            "\t1.33s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3125\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.86s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3029\t = Validation score   (-root_mean_squared_error)\n",
            "\t81.19s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3357\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.39s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2878\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.2766\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.16s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-1.0899\t = Validation score   (-root_mean_squared_error)\n",
            "\t20.1s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.274246\n",
            "[2000]\tvalid_set's rmse: 0.270477\n",
            "[3000]\tvalid_set's rmse: 0.270048\n",
            "[4000]\tvalid_set's rmse: 0.269994\n",
            "[5000]\tvalid_set's rmse: 0.269982\n",
            "[6000]\tvalid_set's rmse: 0.26998\n",
            "[7000]\tvalid_set's rmse: 0.269979\n",
            "[8000]\tvalid_set's rmse: 0.269979\n",
            "[9000]\tvalid_set's rmse: 0.269979\n",
            "[10000]\tvalid_set's rmse: 0.269979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.27\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.26s\t = Training   runtime\n",
            "\t3.27s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.4, 'XGBoost': 0.35, 'LightGBMLarge': 0.15, 'CatBoost': 0.05, 'ExtraTreesMSE': 0.05}\n",
            "\t-0.2018\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 198.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 145.6 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_134555\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_134914\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.86 GB / 12.67 GB (85.7%)\n",
            "Disk Space Avail:   68.80 GB / 107.72 GB (63.9%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_134914\"\n",
            "Train Data Rows:    3550\n",
            "Train Data Columns: 5\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.8, 14.73966, 14.43695)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11121.65 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.14 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 5 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 5 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\t0.1s = Fit runtime\n",
            "\t5 features in original data used to generate 5 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.14 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n",
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14084507042253522, Train Rows: 3050, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-16.4171\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-16.548\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 14.083\n",
            "[2000]\tvalid_set's rmse: 14.0096\n",
            "[3000]\tvalid_set's rmse: 14.0186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-13.9951\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.74s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 13.7511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-13.7227\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.59s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-13.5934\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.36s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-13.6655\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.61s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-13.4265\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.27s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-14.2688\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.93s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-13.9215\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.9s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-14.0494\t = Validation score   (-root_mean_squared_error)\n",
            "\t192.28s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-13.3911\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.92s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'ExtraTreesMSE': 0.476, 'LightGBMLarge': 0.286, 'NeuralNetFastAI': 0.143, 'NeuralNetTorch': 0.095}\n",
            "\t-13.122\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 213.3s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3316.1 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_134914\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결과 파일이 저장되었습니다: TEST_RESULT_1%.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 특징 중요도 추출\n",
        "feature_importance = predictor.feature_importance(train_data)\n",
        "print(\"특징 중요도:\")\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "id": "iiHb_kR1cIzY",
        "outputId": "4ca27012-946d-4526-eff3-e052467513f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iiHb_kR1cIzY",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "These features in provided data are not utilized by the predictor and will be ignored: ['시간단위', '격자명', '경로당 수', 'EPDO', '사고수', 'EPDO 정규화', '사고수 정규화', '종속변수', 'Unnamed: 13', 'EPDO.1', '사고수.1']\n",
            "Computing feature importance via permutation shuffling for 4 features using 3550 rows with 5 shuffle sets...\n",
            "\t14.19s\t= Expected runtime (2.84s per shuffle set)\n",
            "\t6.75s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "특징 중요도:\n",
            "            importance    stddev       p_value  n  p99_high   p99_low\n",
            "과속단속카메라 개수    3.949792  0.091063  3.387973e-08  5  4.137292  3.762293\n",
            "인구수           3.332675  0.034397  1.361571e-09  5  3.403499  3.261851\n",
            "보호구역 개수       1.721941  0.079015  5.305416e-07  5  1.884633  1.559249\n",
            "복지시설 개수       1.405988  0.070441  7.535350e-07  5  1.551027  1.260949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "상위 5% 위험도 변화"
      ],
      "metadata": {
        "id": "cLrXvAbFwNZL"
      },
      "id": "cLrXvAbFwNZL"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "train_path = '/content/drive/MyDrive/노인보호구역 프로젝트/p프_전체계획.xlsx'\n",
        "test_path = '/content/drive/MyDrive/노인보호구역 프로젝트/상위5%보호구역추가.xlsx'\n",
        "\n",
        "train_data = pd.read_excel(train_path)\n",
        "test_data = pd.read_excel(test_path)\n",
        "\n",
        "\n",
        "# 학습할 데이터 준비\n",
        "predictor = TabularPredictor(label='종속').fit(train_data)\n",
        "\n",
        "\n",
        "# 독립변수 열 목록\n",
        "independent_vars = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 독립변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=independent_vars)\n",
        "\n",
        "# 종속변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=[target] + independent_vars)\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인\n",
        "\n",
        "# 2. 학습 데이터 준비\n",
        "target = '종속'\n",
        "features = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 3. AutoGluon 모델 학습\n",
        "predictor = TabularPredictor(label=target).fit(train_data[features + [target]])\n",
        "\n",
        "# 4. 위험도 예측\n",
        "test_data['위험도'] = predictor.predict(test_data[features])\n",
        "\n",
        "# 6. 결과 저장\n",
        "output_path = '상위5%위험도변화.xlsx'\n",
        "test_data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"결과 파일이 저장되었습니다: {output_path}\")"
      ],
      "metadata": {
        "id": "Uh_ro-pXwPG2",
        "outputId": "e71bb280-53a4-4d89-9592-059712b60148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Uh_ro-pXwPG2",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_141218\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.75 GB / 12.67 GB (84.8%)\n",
            "Disk Space Avail:   68.63 GB / 107.72 GB (63.7%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_141218\"\n",
            "Train Data Rows:    3555\n",
            "Train Data Columns: 15\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.0, 14.71893, 14.43737)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11008.91 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.90 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 1): ['Unnamed: 13']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t\t('object', []) :  2 | ['시간단위', '격자명']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['시간단위', '격자명']\n",
            "\t\t('float', [])    : 12 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.29s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14064697609001406, Train Rows: 3055, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-3.8241\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-3.3703\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.907638\n",
            "[2000]\tvalid_set's rmse: 0.756411\n",
            "[3000]\tvalid_set's rmse: 0.691405\n",
            "[4000]\tvalid_set's rmse: 0.655507\n",
            "[5000]\tvalid_set's rmse: 0.629133\n",
            "[6000]\tvalid_set's rmse: 0.611962\n",
            "[7000]\tvalid_set's rmse: 0.599261\n",
            "[8000]\tvalid_set's rmse: 0.591129\n",
            "[9000]\tvalid_set's rmse: 0.584345\n",
            "[10000]\tvalid_set's rmse: 0.579338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5793\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.98s\t = Training   runtime\n",
            "\t2.08s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.559353\n",
            "[2000]\tvalid_set's rmse: 0.535635\n",
            "[3000]\tvalid_set's rmse: 0.525488\n",
            "[4000]\tvalid_set's rmse: 0.522953\n",
            "[5000]\tvalid_set's rmse: 0.521307\n",
            "[6000]\tvalid_set's rmse: 0.520564\n",
            "[7000]\tvalid_set's rmse: 0.520097\n",
            "[8000]\tvalid_set's rmse: 0.519679\n",
            "[9000]\tvalid_set's rmse: 0.519679\n",
            "[10000]\tvalid_set's rmse: 0.519756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.5196\t = Validation score   (-root_mean_squared_error)\n",
            "\t15.97s\t = Training   runtime\n",
            "\t1.31s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-0.3125\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.91s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.3029\t = Validation score   (-root_mean_squared_error)\n",
            "\t80.63s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-0.3357\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.43s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-0.2878\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.95s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.2766\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.36s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-1.0899\t = Validation score   (-root_mean_squared_error)\n",
            "\t19.65s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 0.274246\n",
            "[2000]\tvalid_set's rmse: 0.270477\n",
            "[3000]\tvalid_set's rmse: 0.270048\n",
            "[4000]\tvalid_set's rmse: 0.269994\n",
            "[5000]\tvalid_set's rmse: 0.269982\n",
            "[6000]\tvalid_set's rmse: 0.26998\n",
            "[7000]\tvalid_set's rmse: 0.269979\n",
            "[8000]\tvalid_set's rmse: 0.269979\n",
            "[9000]\tvalid_set's rmse: 0.269979\n",
            "[10000]\tvalid_set's rmse: 0.269979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-0.27\t = Validation score   (-root_mean_squared_error)\n",
            "\t43.21s\t = Training   runtime\n",
            "\t3.86s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.4, 'XGBoost': 0.35, 'LightGBMLarge': 0.15, 'CatBoost': 0.05, 'ExtraTreesMSE': 0.05}\n",
            "\t-0.2018\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 206.95s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 123.3 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_141218\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_141545\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.81 GB / 12.67 GB (85.3%)\n",
            "Disk Space Avail:   68.40 GB / 107.72 GB (63.5%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20241209_141545\"\n",
            "Train Data Rows:    3550\n",
            "Train Data Columns: 5\n",
            "Label Column:       종속\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (96.0, 0.8, 14.73966, 14.43695)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11074.55 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.14 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 5 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 5 | ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
            "\t0.1s = Fit runtime\n",
            "\t5 features in original data used to generate 5 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.14 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.14084507042253522, Train Rows: 3050, Val Rows: 500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n",
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-16.4171\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-16.548\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 14.083\n",
            "[2000]\tvalid_set's rmse: 14.0096\n",
            "[3000]\tvalid_set's rmse: 14.0186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-13.9951\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.92s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's rmse: 13.7511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t-13.7227\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.13s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ...\n",
            "\t-13.5934\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.29s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-13.6655\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.77s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE ...\n",
            "\t-13.4265\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.37s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t-14.2688\t = Validation score   (-root_mean_squared_error)\n",
            "\t4.96s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-13.9215\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t-14.0494\t = Validation score   (-root_mean_squared_error)\n",
            "\t188.96s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t-13.3911\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'ExtraTreesMSE': 0.476, 'LightGBMLarge': 0.286, 'NeuralNetFastAI': 0.143, 'NeuralNetTorch': 0.095}\n",
            "\t-13.122\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 208.54s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3052.2 rows/s (500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20241209_141545\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결과 파일이 저장되었습니다: 상위5%위험도변화.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 특징 중요도 데이터프레임 생성\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': ['경로당 수', '인구수', '과속단속카메라 개수', '복지시설 개수', '보호구역 개수'],\n",
        "    'Importance': [5.806496, 4.973868, 4.670472, 2.343921, 1.762874]\n",
        "})\n",
        "\n",
        "# 중요도 기준으로 내림차순 정렬\n",
        "feature_importance = feature_importance.sort_values(by='Importance', ascending=True)\n",
        "\n",
        "# 그래프 생성\n",
        "colors = ['#D9D9D9', '#B8D0ED', '#558ED5', '#26588A', '#132B45']  # 각 막대의 색상 설정\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(feature_importance['Feature'], feature_importance['Importance'], color=colors, edgecolor='black')\n",
        "\n",
        "# 그래프에 값 표시\n",
        "#for bar in bars:\n",
        "    #width = bar.get_width()\n",
        "    #plt.text(width + 0.1, bar.get_y() + bar.get_height() / 2, f'{width:.2f}', va='center', fontsize=12)\n",
        "\n",
        "\n",
        "# 그래프 표시\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X88lh_Ake8jf",
        "outputId": "2067f116-cfa9-4755-a566-227bdcd27700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "id": "X88lh_Ake8jf",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "train_data = ...\n",
        "\n",
        "# 모델 학습\n",
        "predictor = TabularPredictor(label='종속변수').fit(train_data)\n",
        "\n",
        "# 특징 중요도 추출\n",
        "feature_importance = predictor.feature_importance()\n",
        "\n",
        "# 결과 출력\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "id": "pRrx1ffca8hx",
        "outputId": "c5a63a0d-6904-4e7c-9801-03e6dfa1294a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        }
      },
      "id": "pRrx1ffca8hx",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20241209_123857\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.82 GB / 12.67 GB (85.4%)\n",
            "Disk Space Avail:   71.13 GB / 107.72 GB (66.0%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "train_data is required to be a pandas DataFrame, but was instead: <class 'ellipsis'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-1f0a61cb6c83>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'종속변수'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 특징 중요도 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m             \u001b[0mfeature_generator_init_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         train_data, tuning_data, test_data, unlabeled_data = self._validate_fit_data(\n\u001b[0m\u001b[1;32m   1123\u001b[0m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuning_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munlabeled_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36m_validate_fit_data\u001b[0;34m(self, train_data, tuning_data, test_data, unlabeled_data)\u001b[0m\n\u001b[1;32m   5164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train_data is required to be a pandas DataFrame, but was instead: {type(train_data)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: train_data is required to be a pandas DataFrame, but was instead: <class 'ellipsis'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. 모델 성능 평가\n",
        "performance = predictor.evaluate(train_data)\n",
        "\n",
        "# 8. 주요 성능 지표 출력\n",
        "print(\"\\n=== 모델 성능 평가 ===\")\n",
        "for metric, value in performance.items():\n",
        "    print(f\"{metric}: {value}\")"
      ],
      "metadata": {
        "id": "W4HhgbGTf3oF",
        "outputId": "e79effda-60c1-43af-a650-974310f6bf11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "W4HhgbGTf3oF",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 모델 성능 평가 ===\n",
            "root_mean_squared_error: -8.495990119441695\n",
            "mean_squared_error: -72.1818481096509\n",
            "mean_absolute_error: -5.871398444526139\n",
            "r2: 0.6536030831020705\n",
            "pearsonr: 0.8369441907408084\n",
            "median_absolute_error: -4.398003387451176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.describe())  # 데이터 통계 요약\n",
        "print(train_data.isnull().sum())  # 결측값 확인"
      ],
      "metadata": {
        "id": "dQee6ewRgqRu",
        "outputId": "2ed7a89b-77c2-4cd1-a371-c77dd4ea3ab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dQee6ewRgqRu",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               인구수        경로당 수      복지시설 개수      보호구역 개수   과속단속카메라 개수  \\\n",
            "count  3550.000000  3550.000000  3550.000000  3550.000000  3550.000000   \n",
            "mean   2876.575493     1.982254     1.322254     0.233803     3.179718   \n",
            "std    2285.336045     1.776453     1.357212     0.515727     3.925315   \n",
            "min       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
            "25%     857.250000     0.000000     1.000000     0.000000     0.000000   \n",
            "50%    2542.000000     2.000000     1.000000     0.000000     2.000000   \n",
            "75%    4605.750000     3.000000     1.000000     0.000000     5.000000   \n",
            "max    9226.000000     8.000000    26.000000     3.000000    29.000000   \n",
            "\n",
            "              EPDO          사고수     EPDO 정규화      사고수 정규화         종속변수  \\\n",
            "count  3550.000000  3550.000000  3554.000000  3554.000000  3550.000000   \n",
            "mean     68.782254     1.229014     0.144338     0.032519     0.066252   \n",
            "std      71.672545     0.692676     0.150566     0.099073     0.088761   \n",
            "min       0.000000     1.000000     0.000000    -0.142857     0.000000   \n",
            "25%       9.000000     1.000000     0.018908     0.000000     0.006933   \n",
            "50%      50.000000     1.000000     0.105042     0.000000     0.037815   \n",
            "75%     106.000000     1.000000     0.222689     0.000000     0.087605   \n",
            "max     476.000000     8.000000     1.000000     1.000000     0.754622   \n",
            "\n",
            "                종속  Unnamed: 13      EPDO.1     사고수.1  \n",
            "count  3555.000000          0.0    2.000000  2.000000  \n",
            "mean     14.718931          NaN  238.000000  4.500000  \n",
            "std      14.437370          NaN  336.582828  4.949747  \n",
            "min       0.000000          NaN    0.000000  1.000000  \n",
            "25%       2.600000          NaN  119.000000  2.750000  \n",
            "50%      11.000000          NaN  238.000000  4.500000  \n",
            "75%      22.200000          NaN  357.000000  6.250000  \n",
            "max      96.000000          NaN  476.000000  8.000000  \n",
            "시간단위              5\n",
            "격자명               5\n",
            "인구수               5\n",
            "경로당 수             5\n",
            "복지시설 개수           5\n",
            "보호구역 개수           5\n",
            "과속단속카메라 개수        5\n",
            "EPDO              5\n",
            "사고수               5\n",
            "EPDO 정규화          1\n",
            "사고수 정규화           1\n",
            "종속변수              5\n",
            "종속                0\n",
            "Unnamed: 13    3555\n",
            "EPDO.1         3553\n",
            "사고수.1          3553\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.isnull().sum())"
      ],
      "metadata": {
        "id": "1hCUJ4i2h3qM",
        "outputId": "855d100c-a639-40c1-e5ab-5b48a9d190d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1hCUJ4i2h3qM",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시간단위              5\n",
            "격자명               5\n",
            "인구수               5\n",
            "경로당 수             5\n",
            "복지시설 개수           5\n",
            "보호구역 개수           5\n",
            "과속단속카메라 개수        5\n",
            "EPDO              5\n",
            "사고수               5\n",
            "EPDO 정규화          1\n",
            "사고수 정규화           1\n",
            "종속변수              5\n",
            "종속                0\n",
            "Unnamed: 13    3555\n",
            "EPDO.1         3553\n",
            "사고수.1          3553\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 독립변수 열 목록\n",
        "independent_vars = ['인구수', '경로당 수', '복지시설 개수', '보호구역 개수', '과속단속카메라 개수']\n",
        "\n",
        "# 독립변수 열에 결측값이 있는 행만 삭제\n",
        "train_data = train_data.dropna(subset=independent_vars)\n",
        "\n",
        "# 삭제 후 데이터 크기 확인\n",
        "print(f\"삭제 후 데이터 크기: {train_data.shape}\")\n",
        "print(train_data.isnull().sum())  # 결측값 확인"
      ],
      "metadata": {
        "id": "-lIxZT54xVSZ",
        "outputId": "f53a53c3-ba65-4689-b485-bb8ffc9c5274",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-lIxZT54xVSZ",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제 후 데이터 크기: (3550, 16)\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측값 비율 확인\n",
        "null_percentage = train_data.isnull().mean() * 100\n",
        "print(\"각 열의 결측값 비율(%):\")\n",
        "print(null_percentage.sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "JrH7ms0Jnyjw",
        "outputId": "e698e970-609e-4229-8179-08d80f169d87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JrH7ms0Jnyjw",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 열의 결측값 비율(%):\n",
            "Unnamed: 13    100.000000\n",
            "EPDO.1          99.943662\n",
            "사고수.1           99.943662\n",
            "시간단위             0.000000\n",
            "격자명              0.000000\n",
            "인구수              0.000000\n",
            "경로당 수            0.000000\n",
            "복지시설 개수          0.000000\n",
            "보호구역 개수          0.000000\n",
            "과속단속카메라 개수       0.000000\n",
            "EPDO             0.000000\n",
            "사고수              0.000000\n",
            "EPDO 정규화         0.000000\n",
            "사고수 정규화          0.000000\n",
            "종속변수             0.000000\n",
            "종속               0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 수치형 변수: 평균값으로 대체\n",
        "numerical_cols = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "train_data[numerical_cols] = train_data[numerical_cols].fillna(train_data[numerical_cols].mean())\n",
        "\n",
        "categorical_cols = train_data.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    train_data[col].fillna(train_data[col].mode()[0], inplace=True)\n"
      ],
      "metadata": {
        "id": "Du3l6Rd1n83k",
        "outputId": "d81853c1-6665-4a3a-b368-816d4ce71bd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Du3l6Rd1n83k",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-65-a59f3e0e4766>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train_data[col].fillna(train_data[col].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"결측값 처리 후:\")\n",
        "print(train_data.isnull().sum())\n",
        "print(train_data.describe())"
      ],
      "metadata": {
        "id": "02fb8oNIn-3X",
        "outputId": "ad55b6d7-95b7-4f21-e9b4-db717d940a5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "02fb8oNIn-3X",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결측값 처리 후:\n",
            "시간단위              0\n",
            "격자명               0\n",
            "인구수               0\n",
            "경로당 수             0\n",
            "복지시설 개수           0\n",
            "보호구역 개수           0\n",
            "과속단속카메라 개수        0\n",
            "EPDO              0\n",
            "사고수               0\n",
            "EPDO 정규화          0\n",
            "사고수 정규화           0\n",
            "종속변수              0\n",
            "종속                0\n",
            "Unnamed: 13    3550\n",
            "EPDO.1         3548\n",
            "사고수.1          3548\n",
            "dtype: int64\n",
            "               인구수        경로당 수      복지시설 개수      보호구역 개수   과속단속카메라 개수  \\\n",
            "count  3550.000000  3550.000000  3550.000000  3550.000000  3550.000000   \n",
            "mean   2876.575493     1.982254     1.322254     0.233803     3.179718   \n",
            "std    2285.336045     1.776453     1.357212     0.515727     3.925315   \n",
            "min       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
            "25%     857.250000     0.000000     1.000000     0.000000     0.000000   \n",
            "50%    2542.000000     2.000000     1.000000     0.000000     2.000000   \n",
            "75%    4605.750000     3.000000     1.000000     0.000000     5.000000   \n",
            "max    9226.000000     8.000000    26.000000     3.000000    29.000000   \n",
            "\n",
            "              EPDO          사고수     EPDO 정규화      사고수 정규화         종속변수  \\\n",
            "count  3550.000000  3550.000000  3550.000000  3550.000000  3550.000000   \n",
            "mean     68.782254     1.229014     0.144501     0.032716     0.066252   \n",
            "std      71.672545     0.692676     0.150573     0.098954     0.088761   \n",
            "min       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
            "25%       9.000000     1.000000     0.018908     0.000000     0.006933   \n",
            "50%      50.000000     1.000000     0.105042     0.000000     0.037815   \n",
            "75%     106.000000     1.000000     0.222689     0.000000     0.087605   \n",
            "max     476.000000     8.000000     1.000000     1.000000     0.754622   \n",
            "\n",
            "                종속  Unnamed: 13      EPDO.1     사고수.1  \n",
            "count  3550.000000          0.0    2.000000  2.000000  \n",
            "mean     14.739662          NaN  238.000000  4.500000  \n",
            "std      14.436954          NaN  336.582828  4.949747  \n",
            "min       0.800000          NaN    0.000000  1.000000  \n",
            "25%       2.600000          NaN  119.000000  2.750000  \n",
            "50%      11.000000          NaN  238.000000  4.500000  \n",
            "75%      22.200000          NaN  357.000000  6.250000  \n",
            "max      96.000000          NaN  476.000000  8.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"결측값 처리 후 데이터 크기: {train_data.shape}\")"
      ],
      "metadata": {
        "id": "a3dvgqTeoB5V",
        "outputId": "358e1be9-c944-4fe8-b77e-17da2e2384a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "a3dvgqTeoB5V",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결측값 처리 후 데이터 크기: (3550, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 실제값과 예측값 계산\n",
        "y_true = train_data[target]\n",
        "y_pred = predictor.predict(train_data[features])\n",
        "\n",
        "# 지표 수동 계산\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\n=== 성능 지표 ===\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "id": "gCT0I2k3lcyo",
        "outputId": "3bce45bb-72dd-455d-a134-de30b2c2a8f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gCT0I2k3lcyo",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 성능 지표 ===\n",
            "Mean Squared Error: 74.45244637430295\n",
            "Mean Absolute Error: 6.011766366219858\n",
            "R^2 Score: 0.642685895777024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train_data 정보:\")\n",
        "print(train_data.info())\n",
        "\n",
        "print(\"\\n종속 변수 데이터:\")\n",
        "print(train_data[target].head())\n",
        "\n",
        "print(\"\\n예측값 데이터:\")\n",
        "print(predictor.predict(train_data[features].head()))"
      ],
      "metadata": {
        "id": "ArDOQT9Glroy",
        "outputId": "5bfffed6-3e4f-4ff1-a1d0-d20ad568009f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ArDOQT9Glroy",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data 정보:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3550 entries, 0 to 3553\n",
            "Data columns (total 16 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   시간단위         3550 non-null   object \n",
            " 1   격자명          3550 non-null   object \n",
            " 2   인구수          3550 non-null   float64\n",
            " 3   경로당 수        3550 non-null   float64\n",
            " 4   복지시설 개수      3550 non-null   float64\n",
            " 5   보호구역 개수      3550 non-null   float64\n",
            " 6   과속단속카메라 개수   3550 non-null   float64\n",
            " 7   EPDO         3550 non-null   float64\n",
            " 8   사고수          3550 non-null   float64\n",
            " 9   EPDO 정규화     3550 non-null   float64\n",
            " 10  사고수 정규화      3550 non-null   float64\n",
            " 11  종속변수         3550 non-null   float64\n",
            " 12  종속           3550 non-null   float64\n",
            " 13  Unnamed: 13  0 non-null      float64\n",
            " 14  EPDO.1       2 non-null      float64\n",
            " 15  사고수.1        2 non-null      float64\n",
            "dtypes: float64(14), object(2)\n",
            "memory usage: 471.5+ KB\n",
            "None\n",
            "\n",
            "종속 변수 데이터:\n",
            "0     5.4\n",
            "1    28.2\n",
            "2    27.0\n",
            "3    38.6\n",
            "4    12.2\n",
            "Name: 종속, dtype: float64\n",
            "\n",
            "예측값 데이터:\n",
            "0    11.569682\n",
            "1    15.259163\n",
            "2    25.231623\n",
            "3    25.898111\n",
            "4    10.536996\n",
            "Name: 종속, dtype: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OwXYsbgKlyFq"
      },
      "id": "OwXYsbgKlyFq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}